{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "184f59ff",
   "metadata": {},
   "source": [
    "# Textcuboid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1a65419",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import nltk\n",
    "import re\n",
    "import string\n",
    "import json\n",
    "import keras\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e76cffe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:/Users/user/Desktop/bilm-tf-master/textdataset/WELFake/WELFake_Dataset.csv')\n",
    "\n",
    "df = df.dropna()\n",
    "df.isnull().sum()\n",
    "\n",
    "df.drop(columns=['Unnamed: 0'],inplace=True)\n",
    "\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "X = df.drop(columns=['label'])\n",
    "y = df['label']\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    punctuationfree=\"\".join([i for i in text if i not in string.punctuation])\n",
    "    return punctuationfree\n",
    "\n",
    "X[['title','text']] = X[['title','text']].applymap(lambda x:remove_punctuation(x))\n",
    "X[['title','text']] = X[['title','text']].applymap(lambda x:x.lower())\n",
    "\n",
    "def clean_text(text):\n",
    "    text=str(text).lower() #Converts text to lowercase\n",
    "    text=re.sub('\\d+', '', text) #removes numbers\n",
    "    text=re.sub('\\[.*?\\]', '', text) #removes HTML tags\n",
    "    text=re.sub('https?://\\S+|www\\.\\S+', '', text) #removes url\n",
    "    text=re.sub(r\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", \"\", text) #removes emojis\n",
    "    text=re.sub('[%s]' % re.escape(string.punctuation),'',text) #removes punctuations\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    return text\n",
    "\n",
    "X=X['title']+' '+X['text']\n",
    "\n",
    "X = X.apply(clean_text)\n",
    "\n",
    "X = list(X)\n",
    "\n",
    "pattern = '[^a-z ]'\n",
    "Clean_X=[]\n",
    "for sen in X:\n",
    "    Clean_X.append(re.sub(pattern, '', str(sen)))\n",
    "\n",
    "clean_df = pd.DataFrame({'Clean_X': Clean_X, 'y': y})\n",
    "\n",
    "fake_df = clean_df[clean_df['y'] == 0]\n",
    "real_df = clean_df[clean_df['y'] == 1]\n",
    "\n",
    "fake_x=list(fake_df['Clean_X'])\n",
    "real_x=list(real_df['Clean_X'])\n",
    "\n",
    "real_selected_lst = []\n",
    "fake_selected_lst = []\n",
    "\n",
    "for sen in real_x:\n",
    "    word_count = len(sen.split())\n",
    "    if 10 <= word_count < 2000:\n",
    "        real_selected_lst.append(sen)\n",
    "        \n",
    "for sen in fake_x:\n",
    "    word_count = len(sen.split())\n",
    "    if 10 <= word_count < 2000:\n",
    "        fake_selected_lst.append(sen)\n",
    "\n",
    "X=real_selected_lst[:10000]+fake_selected_lst[:10000]\n",
    "y=[0]*10000+[1]*10000\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "to_txt=x_train+x_test\n",
    "\n",
    "y=y_train+y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4232f2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder=LabelEncoder()\n",
    "\n",
    "encoder.fit(y)\n",
    "\n",
    "label=encoder.transform(y)\n",
    "\n",
    "y_train=list(label[:16000])\n",
    "y_test=list(label[16000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7043559f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#수동으로 cross validation을 하기위한 코드\n",
    "cnt=5  #cnt가 2일때 두번째 시행\n",
    "cnt=cnt-2\n",
    "\n",
    "def exclude_list(input_list, cnt):\n",
    "    return input_list[:cnt*4000]+input_list[cnt*4000+4000:16000]\n",
    "\n",
    "if cnt>-1:\n",
    "    x_train_cnt=exclude_list(x_train,cnt)+x_test\n",
    "    y_train_cnt=exclude_list(y_train,cnt)+y_test\n",
    "    x_test_cnt=x_train[cnt*4000:cnt*4000+4000]\n",
    "    y_test_cnt=y_train[cnt*4000:cnt*4000+4000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c7a896a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if cnt>-1:\n",
    "    x_train=x_train_cnt\n",
    "    y_train=y_train_cnt\n",
    "    x_test=x_test_cnt\n",
    "    y_test=y_test_cnt\n",
    "    to_txt=x_train+x_test\n",
    "    y=y_train+y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02f3e46",
   "metadata": {},
   "source": [
    "## 2) textcuboid 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0fb00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Input, Conv1D, GlobalMaxPooling1D, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ffa92ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "textcuboid=np.load('./1-Channel textcuboid_WELFake(bert).npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55f29d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "textcuboid_test=np.load('./1-Channel textcuboid_test_WELFake(bert).npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "884ef031",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = [[x,y] for x, y in zip(textcuboid, y_train)]\n",
    "random.shuffle(tmp)\n",
    "textcuboid = [n[0] for n in tmp]\n",
    "y_train = [n[1] for n in tmp]\n",
    "textcuboid=np.array(textcuboid)\n",
    "y_train=np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ddec5841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        \"best_model_{epoch}.h5\", save_best_only=False, period=5\n",
    "    ),\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor=\"val_loss\", factor=0.5, patience=2, min_lr=0.0001\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce1b3b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = Input(shape=(53, 768))\n",
    "conv1 = Conv1D(1024, 1, padding='valid', activation='relu')(input_layer)\n",
    "pooling = GlobalMaxPooling1D()(conv1)\n",
    "pooling = Dropout(0.5)(pooling)\n",
    "x = Dense(256, activation='relu')(pooling)\n",
    "x = Dropout(0.5)(x)\n",
    "output_layer = Dense(2, activation='softmax')(x)\n",
    "model = Model(inputs=input_layer, outputs=output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de8bb000",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4cb157c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 53, 768)]         0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 53, 1024)          787456    \n",
      "                                                                 \n",
      " global_max_pooling1d (Globa  (None, 1024)             0         \n",
      " lMaxPooling1D)                                                  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               262400    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 514       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,050,370\n",
      "Trainable params: 1,050,370\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8fa47ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=textcuboid[1000:]\n",
    "x_val=textcuboid[:1000]\n",
    "y_train1=y_train[1000:]\n",
    "y_val=y_train[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3071295",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "59/59 [==============================] - 2s 17ms/step - loss: 1.9613 - accuracy: 0.5366 - val_loss: 0.6853 - val_accuracy: 0.6710 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "59/59 [==============================] - 1s 13ms/step - loss: 0.6192 - accuracy: 0.6539 - val_loss: 0.4526 - val_accuracy: 0.8180 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "59/59 [==============================] - 1s 14ms/step - loss: 0.4295 - accuracy: 0.8055 - val_loss: 0.3063 - val_accuracy: 0.8770 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "59/59 [==============================] - 1s 14ms/step - loss: 0.3238 - accuracy: 0.8655 - val_loss: 0.2945 - val_accuracy: 0.8820 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "59/59 [==============================] - 1s 14ms/step - loss: 0.2712 - accuracy: 0.8894 - val_loss: 0.2229 - val_accuracy: 0.9090 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "59/59 [==============================] - 1s 14ms/step - loss: 0.2252 - accuracy: 0.9107 - val_loss: 0.2039 - val_accuracy: 0.9210 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "59/59 [==============================] - 1s 13ms/step - loss: 0.1981 - accuracy: 0.9227 - val_loss: 0.2026 - val_accuracy: 0.9160 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "59/59 [==============================] - 1s 14ms/step - loss: 0.1641 - accuracy: 0.9393 - val_loss: 0.1803 - val_accuracy: 0.9280 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "59/59 [==============================] - 1s 14ms/step - loss: 0.1294 - accuracy: 0.9525 - val_loss: 0.1849 - val_accuracy: 0.9300 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "59/59 [==============================] - 1s 15ms/step - loss: 0.1061 - accuracy: 0.9622 - val_loss: 0.1863 - val_accuracy: 0.9300 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "59/59 [==============================] - 1s 14ms/step - loss: 0.0820 - accuracy: 0.9702 - val_loss: 0.1955 - val_accuracy: 0.9330 - lr: 5.0000e-04\n",
      "Epoch 12/20\n",
      "59/59 [==============================] - 1s 14ms/step - loss: 0.0663 - accuracy: 0.9792 - val_loss: 0.1950 - val_accuracy: 0.9320 - lr: 5.0000e-04\n",
      "Epoch 13/20\n",
      "59/59 [==============================] - 1s 13ms/step - loss: 0.0548 - accuracy: 0.9812 - val_loss: 0.2224 - val_accuracy: 0.9280 - lr: 2.5000e-04\n",
      "Epoch 14/20\n",
      "59/59 [==============================] - 1s 14ms/step - loss: 0.0456 - accuracy: 0.9858 - val_loss: 0.2247 - val_accuracy: 0.9340 - lr: 2.5000e-04\n",
      "Epoch 15/20\n",
      "59/59 [==============================] - 1s 14ms/step - loss: 0.0400 - accuracy: 0.9867 - val_loss: 0.2240 - val_accuracy: 0.9330 - lr: 1.2500e-04\n",
      "Epoch 16/20\n",
      "59/59 [==============================] - 1s 14ms/step - loss: 0.0358 - accuracy: 0.9877 - val_loss: 0.2345 - val_accuracy: 0.9330 - lr: 1.2500e-04\n",
      "Epoch 17/20\n",
      "59/59 [==============================] - 1s 14ms/step - loss: 0.0335 - accuracy: 0.9893 - val_loss: 0.2337 - val_accuracy: 0.9350 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "59/59 [==============================] - 1s 14ms/step - loss: 0.0295 - accuracy: 0.9913 - val_loss: 0.2363 - val_accuracy: 0.9330 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "59/59 [==============================] - 1s 13ms/step - loss: 0.0315 - accuracy: 0.9903 - val_loss: 0.2411 - val_accuracy: 0.9310 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "59/59 [==============================] - 1s 14ms/step - loss: 0.0278 - accuracy: 0.9913 - val_loss: 0.2444 - val_accuracy: 0.9360 - lr: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train1,callbacks=callbacks, epochs=20,batch_size=256,validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "380d6be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test=np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b8710f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 0s 2ms/step - loss: 0.2194 - accuracy: 0.9377\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.21942150592803955, 0.937749981880188]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(textcuboid_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eb178a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 0s 2ms/step - loss: 0.1684 - accuracy: 0.9330\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1684194952249527, 0.9330000281333923]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = load_model('best_model_10.h5')\n",
    "model.evaluate(textcuboid_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9f3fb4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
