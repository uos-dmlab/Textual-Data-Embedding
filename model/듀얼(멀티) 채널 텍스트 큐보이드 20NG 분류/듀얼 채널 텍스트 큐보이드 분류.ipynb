{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7894be90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#가상환경 cuda로 실행할 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70d9294b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\cuda\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\user\\anaconda3\\envs\\cuda\\lib\\site-packages\\numpy\\.libs\\libopenblas.TXA6YQSD3GCQQC22GEQ54J2UDCXDXHWN.gfortran-win_amd64.dll\n",
      "C:\\Users\\user\\anaconda3\\envs\\cuda\\lib\\site-packages\\numpy\\.libs\\libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ae3aa35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.8.1+cu111'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a03c3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0ec070b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_newsgroup = pd.read_csv('C:/Users/user/Desktop/bilm-tf-master/20news_dataset_clear/20newsgroup_preprocessed.csv', sep=';', usecols=['target', 'text_cleaned'])\n",
    "df_newsgroup.rename(columns={'text_cleaned' : 'text'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f257a98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(df_newsgroup['target'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60ba33b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_newsgroup['target'] = le.transform(df_newsgroup['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ce19dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_newsgroup['text'].astype(str)\n",
    "# y = tf.keras.utils.to_categorical(df_newsgroup['target'], num_classes=df_newsgroup['target'].nunique())\n",
    "y=list(df_newsgroup['target'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=df_newsgroup['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c101037",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "\n",
    "class TextCuboidDataset(Dataset):\n",
    "    def __init__(self, data_dir, labels):\n",
    "        self.data_dir = data_dir\n",
    "        self.labels = labels\n",
    "        self.data = []\n",
    "        \n",
    "        for i in range(14062):\n",
    "            data_path = data_dir+'/cuboid%d.npy'%i\n",
    "            self.data.append(np.load(data_path))\n",
    "            \n",
    "#         print (np.asarray(self.data).shape)\n",
    "#         print (np.asarray(self.label).shape)\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "192a0d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "\n",
    "class ValidDataset(Dataset):\n",
    "    def __init__(self, data_dir, labels):\n",
    "        self.data_dir = data_dir\n",
    "        self.labels = labels\n",
    "        self.data = []\n",
    "        \n",
    "        for i in range(1000):\n",
    "            data_path = data_dir+'/cuboid%d.npy'%(i+14062)\n",
    "            self.data.append(np.load(data_path))\n",
    "            \n",
    "#         print (np.asarray(self.data).shape)\n",
    "#         print (np.asarray(self.label).shape)\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2841b993",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, data_dir, labels):\n",
    "        self.data_dir = data_dir\n",
    "        self.labels = labels\n",
    "        self.data = []\n",
    "        \n",
    "        for i in range(3766):\n",
    "            data_path = data_dir+'/cuboid_test%d.npy'%i\n",
    "            self.data.append(np.load(data_path))\n",
    "            \n",
    "#         print (np.asarray(self.data).shape)\n",
    "#         print (np.asarray(self.label).shape)\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e8f4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TextCuboid(Hub+NG) -> data_dir = 'D:/textcuboid_20ng_dual'\n",
    "#TextCuboid(NG+AG) -> data_dir = 'D:/textcuboid_20ng_dual(ng+ag)'\n",
    "#TextCuboid(Hub+AG) -> data_dir = 'D:/textcuboid_20ng_dual(hub+ag)'\n",
    "data_dir = 'D:/textcuboid_20ng_dual'\n",
    "dataset = TextCuboidDataset(data_dir, y_train[:14062])\n",
    "dataloader = DataLoader(dataset, batch_size=128, shuffle=True)\n",
    "valid = ValidDataset(data_dir, y_train[14062:])\n",
    "validloader = DataLoader(valid, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7360de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        filter_cnt = 1024\n",
    "        self.conv1 = nn.Conv2d(in_channels=2, out_channels=filter_cnt, kernel_size=(1, 1024))\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pooling = nn.AdaptiveMaxPool1d(1)\n",
    "        self.fc1 = nn.Linear(filter_cnt, 512)\n",
    "        self.fc2 = nn.Linear(512, 128)\n",
    "        self.output_layer = nn.Linear(128, 20)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = x.view(-1,x.shape[1],x.shape[2]*x.shape[3])\n",
    "        x = self.pooling(x).view(-1,x.shape[1])\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "#         out=self.output_layer(x)\n",
    "        return self.output_layer(x)\n",
    "\n",
    "model=CNN().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9dfe8ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1        [-1, 1024, 1000, 1]       2,098,176\n",
      "              ReLU-2        [-1, 1024, 1000, 1]               0\n",
      " AdaptiveMaxPool1d-3              [-1, 1024, 1]               0\n",
      "            Linear-4                  [-1, 512]         524,800\n",
      "              ReLU-5                  [-1, 512]               0\n",
      "            Linear-6                  [-1, 128]          65,664\n",
      "              ReLU-7                  [-1, 128]               0\n",
      "            Linear-8                   [-1, 20]           2,580\n",
      "================================================================\n",
      "Total params: 2,691,220\n",
      "Trainable params: 2,691,220\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 7.81\n",
      "Forward/backward pass size (MB): 15.64\n",
      "Params size (MB): 10.27\n",
      "Estimated Total Size (MB): 33.72\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torchsummary\n",
    "torchsummary.summary(model,input_size=(2,1000,1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c620aab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (conv1): Conv2d(2, 1024, kernel_size=(1, 1024), stride=(1, 1))\n",
       "  (relu): ReLU()\n",
       "  (pooling): AdaptiveMaxPool1d(output_size=1)\n",
       "  (fc1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "  (output_layer): Linear(in_features=128, out_features=20, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b00e5591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 배치의 수 : 110\n"
     ]
    }
   ],
   "source": [
    "total_batch = len(dataloader)\n",
    "print('총 배치의 수 : {}'.format(total_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e90aa549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10 Loss: 1.3609846591949464 Accuracy: 57.3460389702745 Val Accuracy: 73.3\n",
      "Epoch: 2/10 Loss: 0.6717881273139606 Accuracy: 78.97169677144076 Val Accuracy: 76.6\n",
      "Epoch: 3/10 Loss: 0.43012711297382006 Accuracy: 86.38884938131133 Val Accuracy: 75.6\n",
      "Epoch: 4/10 Loss: 0.24855137169361113 Accuracy: 92.50462238657374 Val Accuracy: 78.0\n",
      "Epoch: 5/10 Loss: 0.15210925824940205 Accuracy: 95.27094296686104 Val Accuracy: 79.0\n",
      "Epoch: 6/10 Loss: 0.10806188701905987 Accuracy: 96.89944531361115 Val Accuracy: 78.7\n",
      "Epoch: 7/10 Loss: 0.09716141862286763 Accuracy: 97.19101123595506 Val Accuracy: 78.2\n",
      "Epoch: 8/10 Loss: 0.07367420630021529 Accuracy: 97.9021476319158 Val Accuracy: 77.8\n",
      "Epoch: 9/10 Loss: 0.08682059808210893 Accuracy: 97.44702033850092 Val Accuracy: 77.4\n",
      "Epoch: 10/10 Loss: 0.0742378538643772 Accuracy: 97.8025885364813 Val Accuracy: 79.1\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "criterion = CrossEntropyLoss().to(device)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "num_epochs = 10\n",
    "best_val_acc = 0.0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for i, (data,label) in enumerate(dataloader):\n",
    "        data = data.to(device, dtype=torch.float)\n",
    "        label = label.to(device, dtype=torch.long)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += label.size(0)\n",
    "        correct += (predicted == label).sum().item()\n",
    "    # 검증\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (data,label) in enumerate(validloader):\n",
    "            data = data.to(device, dtype=torch.float)\n",
    "            label = label.to(device, dtype=torch.long)\n",
    "\n",
    "            outputs = model(data)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            val_total += label.size(0)\n",
    "            val_correct += (predicted == label).sum().item()\n",
    "    \n",
    "    val_acc=(100 * val_correct / val_total)\n",
    "    print(f'Epoch: {epoch+1}/{num_epochs} Loss: {running_loss/len(dataloader)} Accuracy: {100 * correct / total} Val Accuracy: {val_acc}')\n",
    "#     print(f'Epoch: {epoch+1}/{num_epochs} Loss: {running_loss/len(dataloader)} Accuracy: {100 * correct / total}')\n",
    "\n",
    "    # 검증 정확도가 가장 높은 모델 저장\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), 'D:/save model/dual_best_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4fec6c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'D:/save model/dual_cnn_model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13be36f4",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b050ead2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#마지막 모델\n",
    "model.load_state_dict(torch.load('D:/save model/dual_cnn_model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "304a89f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#베스트 모델\n",
    "model.load_state_dict(torch.load('D:/save model/dual_best_model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7fd3fa98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TextCuboid(Hub+NG) -> test_dir = 'D:/textcuboid_20ng_dual_test'\n",
    "#TextCuboid(NG+AG) -> test_dir = 'D:/textcuboid_20ng_dual(ng+ag)_test'\n",
    "#TextCuboid(Hub+AG) -> test_dir = 'D:/textcuboid_20ng_dual(hub+ag)_test'\n",
    "test_dir = 'D:/textcuboid_20ng_dual_test'\n",
    "testset = TestDataset(test_dir, y_test)\n",
    "testloader = DataLoader(testset, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cab476bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = 'D:/textcuboid_20ng_dual_test(ng+ag)'\n",
    "testset = TestDataset(test_dir, y_test)\n",
    "testloader = DataLoader(testset, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "463f1fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = 'D:/textcuboid_20ng_dual_test(hub+ag)'\n",
    "testset = TestDataset(test_dir, y_test)\n",
    "testloader = DataLoader(testset, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca19bc13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8438\n",
      "accuracy: 0.7734\n",
      "accuracy: 0.7734\n",
      "accuracy: 0.8125\n",
      "accuracy: 0.7812\n",
      "accuracy: 0.7500\n",
      "accuracy: 0.8203\n",
      "accuracy: 0.7891\n",
      "accuracy: 0.7188\n",
      "accuracy: 0.7656\n",
      "accuracy: 0.8516\n",
      "accuracy: 0.8125\n",
      "accuracy: 0.7500\n",
      "accuracy: 0.8359\n",
      "accuracy: 0.8281\n",
      "accuracy: 0.7812\n",
      "accuracy: 0.8125\n",
      "accuracy: 0.8203\n",
      "accuracy: 0.7891\n",
      "accuracy: 0.7812\n",
      "accuracy: 0.7656\n",
      "accuracy: 0.7656\n",
      "accuracy: 0.7891\n",
      "accuracy: 0.7812\n",
      "accuracy: 0.7578\n",
      "accuracy: 0.7734\n",
      "accuracy: 0.8359\n",
      "accuracy: 0.8516\n",
      "accuracy: 0.7891\n",
      "accuracy: 0.8148\n"
     ]
    }
   ],
   "source": [
    "labels = []\n",
    "predicteds = []\n",
    "\n",
    "model.eval ()\n",
    "\n",
    "with torch.no_grad ():\n",
    "    for i, (data, label) in enumerate (testloader):\n",
    "        \n",
    "        data = data.to(device, dtype=torch.float)\n",
    "        label = label.to(device, dtype=torch.long)\n",
    "        \n",
    "        output = model (data)\n",
    "        \n",
    "        _, predicted = torch.max (output, 1)\n",
    "        accuracy = (label==predicted.squeeze()).float().mean()\n",
    "        \n",
    "        labels.extend (label.cpu())\n",
    "        predicteds.extend (predicted.squeeze().cpu())\n",
    "        \n",
    "        print ('accuracy: {:.4f}'.format (accuracy.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2e528fc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.779     0.750     0.764       160\n",
      "           1      0.692     0.749     0.719       195\n",
      "           2      0.645     0.858     0.736       197\n",
      "           3      0.747     0.571     0.647       196\n",
      "           4      0.715     0.771     0.742       192\n",
      "           5      0.875     0.714     0.787       196\n",
      "           6      0.667     0.732     0.698       194\n",
      "           7      0.748     0.884     0.810       198\n",
      "           8      0.925     0.869     0.896       199\n",
      "           9      0.866     0.910     0.887       199\n",
      "          10      0.968     0.905     0.935       200\n",
      "          11      0.927     0.838     0.881       198\n",
      "          12      0.846     0.561     0.675       196\n",
      "          13      0.910     0.864     0.886       198\n",
      "          14      0.861     0.848     0.854       197\n",
      "          15      0.746     0.850     0.794       200\n",
      "          16      0.812     0.808     0.810       182\n",
      "          17      0.945     0.915     0.930       188\n",
      "          18      0.747     0.723     0.734       155\n",
      "          19      0.537     0.683     0.601       126\n",
      "\n",
      "    accuracy                          0.793      3766\n",
      "   macro avg      0.798     0.790     0.789      3766\n",
      "weighted avg      0.804     0.793     0.794      3766\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn import metrics\n",
    "\n",
    "print(metrics.classification_report(labels, predicteds, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d55b1e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1fd60a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97d67ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b462eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15322e30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d129b45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
