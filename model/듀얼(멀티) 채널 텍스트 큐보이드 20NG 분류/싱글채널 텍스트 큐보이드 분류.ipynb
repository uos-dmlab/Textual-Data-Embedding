{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7894be90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#가상환경 cuda로 실행할 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70d9294b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\cuda\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\user\\anaconda3\\envs\\cuda\\lib\\site-packages\\numpy\\.libs\\libopenblas.TXA6YQSD3GCQQC22GEQ54J2UDCXDXHWN.gfortran-win_amd64.dll\n",
      "C:\\Users\\user\\anaconda3\\envs\\cuda\\lib\\site-packages\\numpy\\.libs\\libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ae3aa35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.8.1+cu111'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3da6766f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bcbdb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_newsgroup = pd.read_csv('C:/Users/user/Desktop/bilm-tf-master/20news_dataset_clear/20newsgroup_preprocessed.csv', sep=';', usecols=['target', 'text_cleaned'])\n",
    "df_newsgroup.rename(columns={'text_cleaned' : 'text'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce1daf5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(df_newsgroup['target'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "994bb714",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_newsgroup['target'] = le.transform(df_newsgroup['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20364654",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_newsgroup['text'].astype(str)\n",
    "y = tf.keras.utils.to_categorical(df_newsgroup['target'], num_classes=df_newsgroup['target'].nunique())\n",
    "y=list(df_newsgroup['target'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=df_newsgroup['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c101037",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "\n",
    "class TextCuboidDataset(Dataset):\n",
    "    def __init__(self, data_dir, labels):\n",
    "        self.data_dir = data_dir\n",
    "        self.labels = labels\n",
    "        self.data = []\n",
    "        \n",
    "        for i in range(14062):\n",
    "            data_path = data_dir+'/cuboid%d.npy'%i\n",
    "            self.data.append(np.load(data_path))\n",
    "            \n",
    "#         print (np.asarray(self.data).shape)\n",
    "#         print (np.asarray(self.label).shape)\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49413a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "\n",
    "class ValidDataset(Dataset):\n",
    "    def __init__(self, data_dir, labels):\n",
    "        self.data_dir = data_dir\n",
    "        self.labels = labels\n",
    "        self.data = []\n",
    "        \n",
    "        for i in range(1000):\n",
    "            data_path = data_dir+'/cuboid%d.npy'%(i+14062)\n",
    "            self.data.append(np.load(data_path))\n",
    "            \n",
    "#         print (np.asarray(self.data).shape)\n",
    "#         print (np.asarray(self.label).shape)\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2841b993",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, data_dir, labels):\n",
    "        self.data_dir = data_dir\n",
    "        self.labels = labels\n",
    "        self.data = []\n",
    "        \n",
    "        for i in range(3766):\n",
    "            data_path = data_dir+'/cuboid_test%d.npy'%i\n",
    "            self.data.append(np.load(data_path))\n",
    "            \n",
    "#         print (np.asarray(self.data).shape)\n",
    "#         print (np.asarray(self.label).shape)\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3e8f4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TextCuboid(Hub) -> data_dir = 'D:/textcuboid_all'\n",
    "#TextCuboid(NG) -> data_dir = 'D:/textcuboid_20ng'\n",
    "#TextCuboid(ag) -> data_dir = 'D:/textcuboid_ag'\n",
    "data_dir = 'D:/textcuboid_ag'\n",
    "dataset = TextCuboidDataset(data_dir, y_train[:14062])\n",
    "dataloader = DataLoader(dataset, batch_size=128, shuffle=True)\n",
    "valid = ValidDataset(data_dir, y_train[14062:])\n",
    "validloader = DataLoader(valid, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b7360de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        filter_cnt = 1024\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=filter_cnt, kernel_size=(1, 1024))\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pooling = nn.AdaptiveMaxPool1d(1)\n",
    "        self.fc1 = nn.Linear(filter_cnt, 512)\n",
    "        self.fc2 = nn.Linear(512, 128)\n",
    "        self.output_layer = nn.Linear(128, 20)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = x.view(-1,x.shape[1],x.shape[2]*x.shape[3])\n",
    "        x = self.pooling(x).view(-1,x.shape[1])\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "#         out=self.output_layer(x)\n",
    "        return self.output_layer(x)\n",
    "\n",
    "model=CNN().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d9dfe8ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1        [-1, 1024, 1000, 1]       1,049,600\n",
      "              ReLU-2        [-1, 1024, 1000, 1]               0\n",
      " AdaptiveMaxPool1d-3              [-1, 1024, 1]               0\n",
      "            Linear-4                  [-1, 512]         524,800\n",
      "              ReLU-5                  [-1, 512]               0\n",
      "            Linear-6                  [-1, 128]          65,664\n",
      "              ReLU-7                  [-1, 128]               0\n",
      "            Linear-8                   [-1, 20]           2,580\n",
      "================================================================\n",
      "Total params: 1,642,644\n",
      "Trainable params: 1,642,644\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 3.91\n",
      "Forward/backward pass size (MB): 15.64\n",
      "Params size (MB): 6.27\n",
      "Estimated Total Size (MB): 25.82\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torchsummary\n",
    "torchsummary.summary(model,input_size=(1,1000,1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0c620aab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (conv1): Conv2d(1, 1024, kernel_size=(1, 1024), stride=(1, 1))\n",
       "  (relu): ReLU()\n",
       "  (pooling): AdaptiveMaxPool1d(output_size=1)\n",
       "  (fc1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "  (output_layer): Linear(in_features=128, out_features=20, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b00e5591",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16412\\3989236866.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtotal_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'총 배치의 수 : {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dataloader' is not defined"
     ]
    }
   ],
   "source": [
    "total_batch = len(dataloader)\n",
    "print('총 배치의 수 : {}'.format(total_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04162ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10 Loss: 1.57183797955513 Accuracy: 51.09515004977955 Val Accuracy: 70.9\n",
      "Epoch: 2/10 Loss: 0.7675369425253434 Accuracy: 76.10581709571896 Val Accuracy: 73.3\n",
      "Epoch: 3/10 Loss: 0.4799496095288884 Accuracy: 85.22258569193572 Val Accuracy: 74.8\n",
      "Epoch: 4/10 Loss: 0.26888329440897163 Accuracy: 92.19883373631062 Val Accuracy: 77.5\n",
      "Epoch: 5/10 Loss: 0.15586939972232688 Accuracy: 95.52695206940692 Val Accuracy: 77.5\n",
      "Epoch: 6/10 Loss: 0.11286556675014171 Accuracy: 96.8638884938131 Val Accuracy: 75.6\n",
      "Epoch: 7/10 Loss: 0.08657205996357582 Accuracy: 97.75280898876404 Val Accuracy: 77.1\n",
      "Epoch: 8/10 Loss: 0.06683023809878663 Accuracy: 98.25060446593656 Val Accuracy: 76.9\n",
      "Epoch: 9/10 Loss: 0.05254141898952763 Accuracy: 98.69862039539184 Val Accuracy: 77.7\n",
      "Epoch: 10/10 Loss: 0.04846388679844412 Accuracy: 98.77684539894751 Val Accuracy: 76.7\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "criterion = CrossEntropyLoss().to(device)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "num_epochs = 10\n",
    "best_val_acc = 0.0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for i, (data,label) in enumerate(dataloader):\n",
    "        data = data.to(device, dtype=torch.float)\n",
    "        label = label.to(device, dtype=torch.long)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += label.size(0)\n",
    "        correct += (predicted == label).sum().item()\n",
    "    # 검증\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (data,label) in enumerate(validloader):\n",
    "            data = data.to(device, dtype=torch.float)\n",
    "            label = label.to(device, dtype=torch.long)\n",
    "\n",
    "            outputs = model(data)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            val_total += label.size(0)\n",
    "            val_correct += (predicted == label).sum().item()\n",
    "    \n",
    "    val_acc = 100 * val_correct / val_total\n",
    "    print(f'Epoch: {epoch+1}/{num_epochs} Loss: {running_loss/len(dataloader)} Accuracy: {100 * correct / total} Val Accuracy: {val_acc}')\n",
    "#     print(f'Epoch: {epoch+1}/{num_epochs} Loss: {running_loss/len(dataloader)} Accuracy: {100 * correct / total}')\n",
    "\n",
    "    # 검증 정확도가 가장 높은 모델 저장\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), 'D:/save model/best_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4fec6c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'D:/save model/all_cnn_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b050ead2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#마지막 모델\n",
    "model.load_state_dict(torch.load('D:/save model/all_cnn_model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "abf4b470",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#베스트 모델\n",
    "model.load_state_dict(torch.load('D:/save model/best_model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7fd3fa98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TextCuboid(Hub) -> test_dir = 'D:/textcuboid_all_test'\n",
    "#TextCuboid(NG) -> test_dir = 'D:/textcuboid_20ng_test'\n",
    "#TextCuboid(ag) -> test_dir = 'D:/textcuboid_ag_test'\n",
    "test_dir = 'D:/textcuboid_ag_test'\n",
    "testset = TestDataset(test_dir, y_test)\n",
    "testloader = DataLoader(testset, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ca19bc13",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8594\n",
      "accuracy: 0.7266\n",
      "accuracy: 0.7969\n",
      "accuracy: 0.8047\n",
      "accuracy: 0.7734\n",
      "accuracy: 0.7500\n",
      "accuracy: 0.7969\n",
      "accuracy: 0.7969\n",
      "accuracy: 0.7578\n",
      "accuracy: 0.7891\n",
      "accuracy: 0.8125\n",
      "accuracy: 0.7266\n",
      "accuracy: 0.7188\n",
      "accuracy: 0.7812\n",
      "accuracy: 0.7891\n",
      "accuracy: 0.7891\n",
      "accuracy: 0.7500\n",
      "accuracy: 0.8359\n",
      "accuracy: 0.7500\n",
      "accuracy: 0.8047\n",
      "accuracy: 0.7500\n",
      "accuracy: 0.7734\n",
      "accuracy: 0.7891\n",
      "accuracy: 0.7969\n",
      "accuracy: 0.7109\n",
      "accuracy: 0.6797\n",
      "accuracy: 0.8125\n",
      "accuracy: 0.8672\n",
      "accuracy: 0.7656\n",
      "accuracy: 0.8333\n"
     ]
    }
   ],
   "source": [
    "labels = []\n",
    "predicteds = []\n",
    "\n",
    "model.eval ()\n",
    "\n",
    "with torch.no_grad ():\n",
    "    for i, (data, label) in enumerate (testloader):\n",
    "        \n",
    "        data = data.to(device, dtype=torch.float)\n",
    "        label = label.to(device, dtype=torch.long)\n",
    "        \n",
    "        output = model (data)\n",
    "        \n",
    "        _, predicted = torch.max (output, 1)\n",
    "        accuracy = (label==predicted.squeeze()).float().mean()\n",
    "        \n",
    "        labels.extend (label.cpu())\n",
    "        predicteds.extend (predicted.squeeze().cpu())\n",
    "        \n",
    "        print ('accuracy: {:.4f}'.format (accuracy.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f2e528fc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.762     0.762     0.762       160\n",
      "           1      0.697     0.708     0.702       195\n",
      "           2      0.833     0.711     0.767       197\n",
      "           3      0.568     0.791     0.661       196\n",
      "           4      0.798     0.677     0.732       192\n",
      "           5      0.885     0.628     0.734       196\n",
      "           6      0.588     0.742     0.656       194\n",
      "           7      0.665     0.884     0.759       198\n",
      "           8      0.954     0.834     0.890       199\n",
      "           9      0.920     0.814     0.864       199\n",
      "          10      0.894     0.925     0.909       200\n",
      "          11      0.859     0.864     0.861       198\n",
      "          12      0.805     0.653     0.721       196\n",
      "          13      0.858     0.793     0.824       198\n",
      "          14      0.821     0.863     0.842       197\n",
      "          15      0.799     0.775     0.787       200\n",
      "          16      0.780     0.780     0.780       182\n",
      "          17      0.919     0.910     0.914       188\n",
      "          18      0.700     0.768     0.732       155\n",
      "          19      0.658     0.627     0.642       126\n",
      "\n",
      "    accuracy                          0.779      3766\n",
      "   macro avg      0.788     0.775     0.777      3766\n",
      "weighted avg      0.792     0.779     0.780      3766\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn import metrics\n",
    "\n",
    "print(metrics.classification_report(labels, predicteds, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d55b1e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1fd60a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97d67ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b462eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15322e30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d129b45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
