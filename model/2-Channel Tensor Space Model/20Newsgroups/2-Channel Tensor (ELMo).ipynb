{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "184f59ff",
   "metadata": {},
   "source": [
    "# 패키지 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c3f37ac-48cb-4e83-a23c-b9d863265cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import nltk\n",
    "import os\n",
    "import string\n",
    "import re\n",
    "import json\n",
    "import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Input, Conv1D, GlobalMaxPooling1D, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Attention\n",
    "from keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from transformer_build import  *\n",
    "from data_preprocessing import *\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c61eba1",
   "metadata": {},
   "source": [
    "# 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "849c1414",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_newsgroup = pd.read_csv('C:/Users/user/Desktop/bilm-tf-master/20news_dataset_clear/20newsgroup_preprocessed.csv', sep=';', usecols=['target', 'text_cleaned'])\n",
    "df_newsgroup.rename(columns={'text_cleaned' : 'text'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c1853e-a011-486a-ad3c-7a52a9e0058c",
   "metadata": {},
   "outputs": [],
   "source": [
    "textcuboid=np.load('./1-Channel textcuboid_20ng(elmo).npy')\n",
    "textcuboid_test=np.load('./1-Channel textcuboid_test_20ng(elmo).npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f977ea-f1c2-48ce-b159-40e9c346108e",
   "metadata": {},
   "source": [
    "# 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20182c08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LabelEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LabelEncoder</label><div class=\"sk-toggleable__content\"><pre>LabelEncoder()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(df_newsgroup['target'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d00d3c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_newsgroup['target'] = le.transform(df_newsgroup['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7aa761db",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_newsgroup['text'].astype(str)\n",
    "y=list(df_newsgroup['target'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=df_newsgroup['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "532b2e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=list(X_train)\n",
    "x_test=list(X_test)\n",
    "\n",
    "sos_x_train=[]\n",
    "sos_x_test=[]\n",
    "for sen in x_train:\n",
    "    sos_x_train.append('<sos> '+sen)\n",
    "for sen in x_test:\n",
    "    sos_x_test.append('<sos> '+sen)\n",
    "\n",
    "all_txt=sos_x_train+sos_x_test\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(all_txt)\n",
    "\n",
    "vocab_size =len(tokenizer.word_index)+1 #1을 더해야 에러가 안터짐 토큰 영향으로 보임\n",
    "\n",
    "x_train_encoded = tokenizer.texts_to_sequences(sos_x_train)\n",
    "x_test_encoded = tokenizer.texts_to_sequences(sos_x_test)\n",
    "\n",
    "max_len = 300\n",
    "\n",
    "xtext_train = tf.keras.preprocessing.sequence.pad_sequences(x_train_encoded, maxlen=max_len)\n",
    "xtext_test = tf.keras.preprocessing.sequence.pad_sequences(x_test_encoded, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "509aa871",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_train_labels = to_categorical(y_train)\n",
    "one_hot_test_labels = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8fa47ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "textcuboid_train=textcuboid[1000:]\n",
    "text_train=xtext_train[1000:]\n",
    "textcuboid__val=textcuboid[:1000]\n",
    "text_val=xtext_train[:1000]\n",
    "y_train=one_hot_train_labels[1000:]\n",
    "y_val=one_hot_train_labels[:1000]\n",
    "\n",
    "text_test=xtext_test\n",
    "y_test=one_hot_test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02f3e46",
   "metadata": {},
   "source": [
    "# 모델  빌드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ddec5841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        \"best_model_{epoch}.h5\", save_best_only=False, period=5\n",
    "    ),\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor=\"val_loss\", factor=0.5, patience=2, min_lr=0.0001\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b21b2ac-f2ee-451a-8e21-0f35d5cf1af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 300)]        0           []                               \n",
      "                                                                                                  \n",
      " token_and_position_embedding (  (None, 300, 384)    58118400    ['input_2[0][0]']                \n",
      " TokenAndPositionEmbedding)                                                                       \n",
      "                                                                                                  \n",
      " input_1 (InputLayer)           [(None, 952, 256)]   0           []                               \n",
      "                                                                                                  \n",
      " transformer_block (Transformer  (None, 300, 384)    617888      ['token_and_position_embedding[0]\n",
      " Block)                                                          [0]']                            \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 952, 256)     65792       ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " global_average_pooling1d (Glob  (None, 384)         0           ['transformer_block[0][0]']      \n",
      " alAveragePooling1D)                                                                              \n",
      "                                                                                                  \n",
      " global_max_pooling1d (GlobalMa  (None, 256)         0           ['conv1d[0][0]']                 \n",
      " xPooling1D)                                                                                      \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 384)          0           ['global_average_pooling1d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 256)          65792       ['global_max_pooling1d[0][0]']   \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 256)          98560       ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 512)          0           ['dense[0][0]',                  \n",
      "                                                                  'dense_7[0][0]']                \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 20)           10260       ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 58,976,692\n",
      "Trainable params: 58,976,692\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 384 # 단어의 임베딩 벡터의 차원\n",
    "num_heads = 1  # 어텐션 헤드의 수\n",
    "dff = 32  # 포지션 와이즈 피드 포워드 신경망의 은닉층의 크기\n",
    "num_transformer_blocks = 1\n",
    "\n",
    "#ELMo channel의 학습\n",
    "ELMo_input = Input(shape=(952, 256))\n",
    "conv1 = Conv1D(256, 1, padding='valid', activation='relu')(ELMo_input)\n",
    "pooling = GlobalMaxPooling1D()(conv1)\n",
    "# pooling = Dropout(0.5)(pooling)\n",
    "ELMo_x = Dense(256, activation='relu')(pooling)\n",
    "# ELMo_attention_layer = Attention()\n",
    "# ELMo_a=ELMo_attention_layer([ELMo_x,ELMo_x])\n",
    "\n",
    "#Sequence channel의 학습\n",
    "Text_inputs = Input(shape=(max_len,))\n",
    "embedding_layer = TokenAndPositionEmbedding(max_len, vocab_size, embedding_dim)\n",
    "Text_x = embedding_layer(Text_inputs)\n",
    "\n",
    "for _ in range(num_transformer_blocks):\n",
    "    transformer_block = TransformerBlock(embedding_dim, num_heads, dff)\n",
    "    Text_x = transformer_block(Text_x)\n",
    "\n",
    "Text_x = tf.keras.layers.GlobalAveragePooling1D()(Text_x)\n",
    "Text_x = tf.keras.layers.Dropout(0.5)(Text_x)\n",
    "Text_x = tf.keras.layers.Dense(256, activation=\"relu\")(Text_x)\n",
    "# Text_attention_layer = Attention()\n",
    "# Text_a=Text_attention_layer([Text_x,Text_x])\n",
    "\n",
    "#결합 후 분류\n",
    "# x = layers.concatenate([ELMo_x,ELMo_a, Text_x,Text_a], axis=-1)\n",
    "# x = layers.concatenate([ELMo_a, Text_a], axis=-1)\n",
    "x = layers.concatenate([ELMo_x, Text_x], axis=-1)\n",
    "# x = Dropout(0.5)(x)\n",
    "output_layer = Dense(20, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=[ELMo_input, Text_inputs], outputs=output_layer)\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bdd9d3bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "55/55 [==============================] - 16s 240ms/step - loss: 2.2173 - accuracy: 0.3561 - val_loss: 1.0749 - val_accuracy: 0.6940 - lr: 0.0010\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'model/transformer_block_3/dropout_7/dropout/Mul' defined at (most recent call last):\n    File \"C:\\ProgramData\\anaconda3\\envs\\class\\lib\\runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\ProgramData\\anaconda3\\envs\\class\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\ProgramData\\anaconda3\\envs\\class\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\ProgramData\\anaconda3\\envs\\class\\lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n      app.start()\n    File \"C:\\ProgramData\\anaconda3\\envs\\class\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 701, in start\n      self.io_loop.start()\n    File \"C:\\ProgramData\\anaconda3\\envs\\class\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\ProgramData\\anaconda3\\envs\\class\\lib\\asyncio\\windows_events.py\", line 316, in run_forever\n      super().run_forever()\n    File \"C:\\ProgramData\\anaconda3\\envs\\class\\lib\\asyncio\\base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"C:\\ProgramData\\anaconda3\\envs\\class\\lib\\asyncio\\base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"C:\\ProgramData\\anaconda3\\envs\\class\\lib\\asyncio\\events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\ProgramData\\anaconda3\\envs\\class\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in dispatch_queue\n      await self.process_one()\n    File \"C:\\ProgramData\\anaconda3\\envs\\class\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 523, in process_one\n      await dispatch(*args)\n    File \"C:\\ProgramData\\anaconda3\\envs\\class\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 429, in dispatch_shell\n      await result\n    File \"C:\\ProgramData\\anaconda3\\envs\\class\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 767, in execute_request\n      reply_content = await reply_content\n    File \"C:\\ProgramData\\anaconda3\\envs\\class\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 429, in do_execute\n      res = shell.run_cell(\n    File \"C:\\ProgramData\\anaconda3\\envs\\class\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\ProgramData\\anaconda3\\envs\\class\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"C:\\ProgramData\\anaconda3\\envs\\class\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"C:\\ProgramData\\anaconda3\\envs\\class\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\ProgramData\\anaconda3\\envs\\class\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\ProgramData\\anaconda3\\envs\\class\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\ProgramData\\anaconda3\\envs\\class\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_10920\\2312256355.py\", line 1, in <module>\n      history = model.fit([textcuboid_train,text_train], y_train,callbacks=callbacks, epochs=50,batch_size=256,validation_data=([textcuboid__val,text_val], y_val))\n    File \"C:\\ProgramData\\anaconda3\\envs\\class\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\ProgramData\\anaconda3\\envs\\class\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\ProgramData\\anaconda3\\envs\\class\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"C:\\ProgramData\\anaconda3\\envs\\class\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\ProgramData\\anaconda3\\envs\\class\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\ProgramData\\anaconda3\\envs\\class\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n      y_pred = self(x, training=True)\n    File \"C:\\ProgramData\\anaconda3\\envs\\class\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\ProgramData\\anaconda3\\envs\\class\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"C:\\ProgramData\\anaconda3\\envs\\class\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\ProgramData\\anaconda3\\envs\\class\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\ProgramData\\anaconda3\\envs\\class\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\ProgramData\\anaconda3\\envs\\class\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"C:\\ProgramData\\anaconda3\\envs\\class\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"C:\\ProgramData\\anaconda3\\envs\\class\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\ProgramData\\anaconda3\\envs\\class\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\ProgramData\\anaconda3\\envs\\class\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_10920\\3963287532.py\", line 75, in call\n      ffn_output = self.dropout2(ffn_output, training=training)\n    File \"C:\\ProgramData\\anaconda3\\envs\\class\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\ProgramData\\anaconda3\\envs\\class\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\ProgramData\\anaconda3\\envs\\class\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\ProgramData\\anaconda3\\envs\\class\\lib\\site-packages\\keras\\layers\\regularization\\dropout.py\", line 116, in call\n      output = control_flow_util.smart_cond(\n    File \"C:\\ProgramData\\anaconda3\\envs\\class\\lib\\site-packages\\keras\\utils\\control_flow_util.py\", line 108, in smart_cond\n      return tf.__internal__.smart_cond.smart_cond(\n    File \"C:\\ProgramData\\anaconda3\\envs\\class\\lib\\site-packages\\keras\\layers\\regularization\\dropout.py\", line 112, in dropped_inputs\n      return self._random_generator.dropout(\n    File \"C:\\ProgramData\\anaconda3\\envs\\class\\lib\\site-packages\\keras\\backend.py\", line 2162, in dropout\n      return tf.nn.dropout(\nNode: 'model/transformer_block_3/dropout_7/dropout/Mul'\nfailed to allocate memory\n\t [[{{node model/transformer_block_3/dropout_7/dropout/Mul}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_8711]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtextcuboid_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtext_train\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtextcuboid__val\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtext_val\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\class\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\class\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'model/transformer_block_3/dropout_7/dropout/Mul' defined at (most recent call last):\n    File \"C:\\ProgramData\\anaconda3\\envs\\class\\lib\\runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\ProgramData\\anaconda3\\envs\\class\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\ProgramData\\anaconda3\\envs\\class\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\ProgramData\\anaconda3\\envs\\class\\lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n      app.start()\n    File \"C:\\ProgramData\\anaconda3\\envs\\class\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 701, in start\n      self.io_loop.start()\n    File \"C:\\ProgramData\\anaconda3\\envs\\class\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\ProgramData\\anaconda3\\envs\\class\\lib\\asyncio\\windows_events.py\", line 316, in run_forever\n      super().run_forever()\n    File \"C:\\ProgramData\\anaconda3\\envs\\class\\lib\\asyncio\\base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"C:\\ProgramData\\anaconda3\\envs\\class\\lib\\asyncio\\base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"C:\\ProgramData\\anaconda3\\envs\\class\\lib\\asyncio\\events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\ProgramData\\anaconda3\\envs\\class\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in dispatch_queue\n      await self.process_one()\n    File \"C:\\ProgramData\\anaconda3\\envs\\class\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 523, in process_one\n      await dispatch(*args)\n    File \"C:\\ProgramData\\anaconda3\\envs\\class\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 429, in dispatch_shell\n      await result\n    File \"C:\\ProgramData\\anaconda3\\envs\\class\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 767, in execute_request\n      reply_content = await reply_content\n    File \"C:\\ProgramData\\anaconda3\\envs\\class\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 429, in do_execute\n      res = shell.run_cell(\n    File \"C:\\ProgramData\\anaconda3\\envs\\class\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\ProgramData\\anaconda3\\envs\\class\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"C:\\ProgramData\\anaconda3\\envs\\class\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"C:\\ProgramData\\anaconda3\\envs\\class\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\ProgramData\\anaconda3\\envs\\class\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\ProgramData\\anaconda3\\envs\\class\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\ProgramData\\anaconda3\\envs\\class\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_10920\\2312256355.py\", line 1, in <module>\n      history = model.fit([textcuboid_train,text_train], y_train,callbacks=callbacks, epochs=50,batch_size=256,validation_data=([textcuboid__val,text_val], y_val))\n    File \"C:\\ProgramData\\anaconda3\\envs\\class\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\ProgramData\\anaconda3\\envs\\class\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\ProgramData\\anaconda3\\envs\\class\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"C:\\ProgramData\\anaconda3\\envs\\class\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\ProgramData\\anaconda3\\envs\\class\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\ProgramData\\anaconda3\\envs\\class\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n      y_pred = self(x, training=True)\n    File \"C:\\ProgramData\\anaconda3\\envs\\class\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\ProgramData\\anaconda3\\envs\\class\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"C:\\ProgramData\\anaconda3\\envs\\class\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\ProgramData\\anaconda3\\envs\\class\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\ProgramData\\anaconda3\\envs\\class\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\ProgramData\\anaconda3\\envs\\class\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"C:\\ProgramData\\anaconda3\\envs\\class\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"C:\\ProgramData\\anaconda3\\envs\\class\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\ProgramData\\anaconda3\\envs\\class\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\ProgramData\\anaconda3\\envs\\class\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_10920\\3963287532.py\", line 75, in call\n      ffn_output = self.dropout2(ffn_output, training=training)\n    File \"C:\\ProgramData\\anaconda3\\envs\\class\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\ProgramData\\anaconda3\\envs\\class\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\ProgramData\\anaconda3\\envs\\class\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\ProgramData\\anaconda3\\envs\\class\\lib\\site-packages\\keras\\layers\\regularization\\dropout.py\", line 116, in call\n      output = control_flow_util.smart_cond(\n    File \"C:\\ProgramData\\anaconda3\\envs\\class\\lib\\site-packages\\keras\\utils\\control_flow_util.py\", line 108, in smart_cond\n      return tf.__internal__.smart_cond.smart_cond(\n    File \"C:\\ProgramData\\anaconda3\\envs\\class\\lib\\site-packages\\keras\\layers\\regularization\\dropout.py\", line 112, in dropped_inputs\n      return self._random_generator.dropout(\n    File \"C:\\ProgramData\\anaconda3\\envs\\class\\lib\\site-packages\\keras\\backend.py\", line 2162, in dropout\n      return tf.nn.dropout(\nNode: 'model/transformer_block_3/dropout_7/dropout/Mul'\nfailed to allocate memory\n\t [[{{node model/transformer_block_3/dropout_7/dropout/Mul}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_8711]"
     ]
    }
   ],
   "source": [
    "history = model.fit([textcuboid_train,text_train], y_train,callbacks=callbacks, epochs=50,batch_size=256,validation_data=([textcuboid__val,text_val], y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8710f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate([textcuboid_test,text_test],y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb178a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "custom_objects = {\"TokenAndPositionEmbedding\": TokenAndPositionEmbedding, \"TransformerBlock\": TransformerBlock}\n",
    "model = load_model('best_model_45.h5', custom_objects=custom_objects)\n",
    "model.evaluate([textcuboid_test,text_test],y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84860aeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
