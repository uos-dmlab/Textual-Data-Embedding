{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "184f59ff",
   "metadata": {},
   "source": [
    "# Textcuboid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "849c1414",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import nltk\n",
    "import re\n",
    "import string\n",
    "import json\n",
    "import keras\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0128117",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:/Users/user/Desktop/bilm-tf-master/textdataset/WELFake/WELFake_Dataset.csv')\n",
    "\n",
    "df = df.dropna()\n",
    "df.isnull().sum()\n",
    "\n",
    "df.drop(columns=['Unnamed: 0'],inplace=True)\n",
    "\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "X = df.drop(columns=['label'])\n",
    "y = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32b8f1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    punctuationfree=\"\".join([i for i in text if i not in string.punctuation])\n",
    "    return punctuationfree\n",
    "\n",
    "X[['title','text']] = X[['title','text']].applymap(lambda x:remove_punctuation(x))\n",
    "X[['title','text']] = X[['title','text']].applymap(lambda x:x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15fc50f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text=str(text).lower() #Converts text to lowercase\n",
    "    text=re.sub('\\d+', '', text) #removes numbers\n",
    "    text=re.sub('\\[.*?\\]', '', text) #removes HTML tags\n",
    "    text=re.sub('https?://\\S+|www\\.\\S+', '', text) #removes url\n",
    "    text=re.sub(r\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", \"\", text) #removes emojis\n",
    "    text=re.sub('[%s]' % re.escape(string.punctuation),'',text) #removes punctuations\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b03e282",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X['title']+' '+X['text']\n",
    "\n",
    "X = X.apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b23b1528",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = list(X)\n",
    "\n",
    "pattern = '[^a-z ]'\n",
    "Clean_X=[]\n",
    "for sen in X:\n",
    "    Clean_X.append(re.sub(pattern, '', str(sen)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "008e1b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = pd.DataFrame({'Clean_X': Clean_X, 'y': y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0033f31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_df = clean_df[clean_df['y'] == 0]\n",
    "real_df = clean_df[clean_df['y'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8f9a14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_x=list(fake_df['Clean_X'])\n",
    "real_x=list(real_df['Clean_X'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c55eee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_selected_lst = []\n",
    "fake_selected_lst = []\n",
    "\n",
    "for sen in real_x:\n",
    "    word_count = len(sen.split())\n",
    "    if 10 <= word_count < 2000:\n",
    "        real_selected_lst.append(sen)\n",
    "        \n",
    "for sen in fake_x:\n",
    "    word_count = len(sen.split())\n",
    "    if 10 <= word_count < 2000:\n",
    "        fake_selected_lst.append(sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "104021b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=real_selected_lst[:10000]+fake_selected_lst[:10000]\n",
    "y=[0]*10000+[1]*10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2963a406",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8f9259a",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_txt=x_train+x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86b76d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=y_train+y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5dfc9762",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder=LabelEncoder()\n",
    "\n",
    "encoder.fit(y)\n",
    "\n",
    "label=encoder.transform(y)\n",
    "\n",
    "y_train=list(label[:16000])\n",
    "y_test=list(label[16000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8a52282",
   "metadata": {},
   "outputs": [],
   "source": [
    "#수동으로 cross validation을 하기위한 코드\n",
    "cnt=5  #cnt가 2일때 두번째 시행\n",
    "cnt=cnt-2\n",
    "\n",
    "def exclude_list(input_list, cnt):\n",
    "    return input_list[:cnt*4000]+input_list[cnt*4000+4000:16000]\n",
    "\n",
    "if cnt>-1:\n",
    "    x_train_cnt=exclude_list(x_train,cnt)+x_test\n",
    "    y_train_cnt=exclude_list(y_train,cnt)+y_test\n",
    "    x_test_cnt=x_train[cnt*4000:cnt*4000+4000]\n",
    "    y_test_cnt=y_train[cnt*4000:cnt*4000+4000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce513665",
   "metadata": {},
   "outputs": [],
   "source": [
    "#텍스트 큐보이드 생성을 위한 인덱스\n",
    "def train_idx_list(cnt):\n",
    "    original_train_lst=[i for i in range(16000)]\n",
    "    return original_train_lst[:cnt*4000]+original_train_lst[cnt*4000+4000:16000]\n",
    "\n",
    "def test_idx_list(cnt):\n",
    "    original_train_lst=[i for i in range(16000)]\n",
    "    return original_train_lst[cnt*4000:cnt*4000+4000]\n",
    "    \n",
    "if cnt>-1:\n",
    "    train_idx=train_idx_list(cnt)\n",
    "    test_idx=test_idx_list(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "39504c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#불용어 불러오기\n",
    "with open('C:/Users/user/Desktop/english.txt', 'r', encoding='utf-8') as file:\n",
    "    stopwords = [line.strip() for line in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b8c0c41a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'daren', 'hadn', 'herse', 'himse', 'itse', 'mayn', 'mightn', 'mon', 'mustn', 'myse', 'needn', 'oughtn', 'shan'] not in stop_words.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer(stop_words=stopwords)\n",
    "X_dtm = vect.fit_transform(to_txt)\n",
    "X_dtm = X_dtm.toarray()\n",
    "X_new = SelectKBest(chi2, k=10000).fit(X_dtm, y)\n",
    "TorF = X_new.get_support()\n",
    "TorF\n",
    "import numpy as np\n",
    "word_view=np.array(vect.get_feature_names())\n",
    "sw=word_view[TorF]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c530d167",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['aap', 'aaplo', 'aaronkleinshow', ..., 'zuesse', 'zuma', 'zur'],\n",
       "      dtype='<U157')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#선별된 10000개 단어\n",
    "sw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9b6b8cae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aap',\n",
       " 'aaplo',\n",
       " 'aaronkleinshow',\n",
       " 'ababa',\n",
       " 'abadi',\n",
       " 'abandon',\n",
       " 'abandoned',\n",
       " 'abbas',\n",
       " 'abbasi',\n",
       " 'abc',\n",
       " 'abcpolitics',\n",
       " 'abcs',\n",
       " 'abdel',\n",
       " 'abdelhafiz',\n",
       " 'abdeslam',\n",
       " 'abdrabbu',\n",
       " 'abducted',\n",
       " 'abductions',\n",
       " 'abdulazeez',\n",
       " 'abdullah',\n",
       " 'abdullahi',\n",
       " 'abe',\n",
       " 'abedi',\n",
       " 'abedin',\n",
       " 'abedins',\n",
       " 'aber',\n",
       " 'abes',\n",
       " 'abid',\n",
       " 'abidjan',\n",
       " 'ability',\n",
       " 'ablebodied',\n",
       " 'aboard',\n",
       " 'abongo',\n",
       " 'abortion',\n",
       " 'abortions',\n",
       " 'abramovic',\n",
       " 'abrams',\n",
       " 'absence',\n",
       " 'absentee',\n",
       " 'absentia',\n",
       " 'absolute',\n",
       " 'absolutely',\n",
       " 'abstention',\n",
       " 'abu',\n",
       " 'abuja',\n",
       " 'abundance',\n",
       " 'abuser',\n",
       " 'abuses',\n",
       " 'aca',\n",
       " 'academics',\n",
       " 'academies',\n",
       " 'academy',\n",
       " 'acasabotage',\n",
       " 'accelerate',\n",
       " 'accelerated',\n",
       " 'accept',\n",
       " 'accepted',\n",
       " 'accession',\n",
       " 'accident',\n",
       " 'accidentally',\n",
       " 'accommodating',\n",
       " 'accompanied',\n",
       " 'accomplished',\n",
       " 'accord',\n",
       " 'accords',\n",
       " 'accounts',\n",
       " 'accuracy',\n",
       " 'accurate',\n",
       " 'accusations',\n",
       " 'accused',\n",
       " 'accuser',\n",
       " 'achievement',\n",
       " 'acid',\n",
       " 'acidic',\n",
       " 'ackman',\n",
       " 'acknowledged',\n",
       " 'acknowledgment',\n",
       " 'acne',\n",
       " 'acorn',\n",
       " 'acquired',\n",
       " 'acquisition',\n",
       " 'acr',\n",
       " 'acres',\n",
       " 'acrimonious',\n",
       " 'acronym',\n",
       " 'action',\n",
       " 'activation',\n",
       " 'activists',\n",
       " 'activity',\n",
       " 'actual',\n",
       " 'actuaries',\n",
       " 'actuary',\n",
       " 'acu',\n",
       " 'acumen',\n",
       " 'acupuncture',\n",
       " 'acute',\n",
       " 'adamshawny',\n",
       " 'adan',\n",
       " 'adaptation',\n",
       " 'addedthe',\n",
       " 'addicting',\n",
       " 'adding',\n",
       " 'additional',\n",
       " 'additionally',\n",
       " 'address',\n",
       " 'addressed',\n",
       " 'addressing',\n",
       " 'aden',\n",
       " 'adequately',\n",
       " 'adjacent',\n",
       " 'adjust',\n",
       " 'adjustability',\n",
       " 'adjusted',\n",
       " 'adjusting',\n",
       " 'adjustment',\n",
       " 'adjustments',\n",
       " 'adltabatabai',\n",
       " 'admin',\n",
       " 'administration',\n",
       " 'administrations',\n",
       " 'administrative',\n",
       " 'administrator',\n",
       " 'admirers',\n",
       " 'admit',\n",
       " 'admits',\n",
       " 'admitted',\n",
       " 'admitting',\n",
       " 'adolph',\n",
       " 'adopt',\n",
       " 'adopting',\n",
       " 'advance',\n",
       " 'advanced',\n",
       " 'advances',\n",
       " 'advancing',\n",
       " 'advantage',\n",
       " 'adventure',\n",
       " 'adversaries',\n",
       " 'advertisement',\n",
       " 'advertising',\n",
       " 'advised',\n",
       " 'adviser',\n",
       " 'advisers',\n",
       " 'advises',\n",
       " 'advising',\n",
       " 'advisor',\n",
       " 'advisory',\n",
       " 'advocacy',\n",
       " 'advocates',\n",
       " 'afari',\n",
       " 'afd',\n",
       " 'affair',\n",
       " 'affairs',\n",
       " 'affect',\n",
       " 'affirmed',\n",
       " 'affleck',\n",
       " 'affluent',\n",
       " 'affordability',\n",
       " 'affordable',\n",
       " 'afghan',\n",
       " 'afghanistan',\n",
       " 'afghanistans',\n",
       " 'aflcio',\n",
       " 'aforementioned',\n",
       " 'afp',\n",
       " 'afraid',\n",
       " 'africa',\n",
       " 'african',\n",
       " 'africanamerican',\n",
       " 'africanamericans',\n",
       " 'africans',\n",
       " 'afrin',\n",
       " 'afternoon',\n",
       " 'aftershocks',\n",
       " 'aftertrumpimplodes',\n",
       " 'afterward',\n",
       " 'agencies',\n",
       " 'agency',\n",
       " 'agencys',\n",
       " 'agent',\n",
       " 'agents',\n",
       " 'aggressive',\n",
       " 'aggressively',\n",
       " 'aging',\n",
       " 'agitators',\n",
       " 'agorist',\n",
       " 'agreed',\n",
       " 'agreement',\n",
       " 'agreements',\n",
       " 'agricultural',\n",
       " 'agriculture',\n",
       " 'agua',\n",
       " 'agung',\n",
       " 'ahem',\n",
       " 'ahmed',\n",
       " 'ahmet',\n",
       " 'ahok',\n",
       " 'ahole',\n",
       " 'ahora',\n",
       " 'aht',\n",
       " 'aid',\n",
       " 'aide',\n",
       " 'aides',\n",
       " 'aig',\n",
       " 'ailes',\n",
       " 'ailess',\n",
       " 'aim',\n",
       " 'aimed',\n",
       " 'aiming',\n",
       " 'aims',\n",
       " 'ain',\n",
       " 'ainsi',\n",
       " 'air',\n",
       " 'airbag',\n",
       " 'airbags',\n",
       " 'airbnb',\n",
       " 'airboat',\n",
       " 'airbus',\n",
       " 'aircraft',\n",
       " 'aires',\n",
       " 'airfield',\n",
       " 'airline',\n",
       " 'airlines',\n",
       " 'airport',\n",
       " 'airports',\n",
       " 'airs',\n",
       " 'airstrikes',\n",
       " 'airways',\n",
       " 'aisyah',\n",
       " 'aj',\n",
       " 'ajamu',\n",
       " 'aka',\n",
       " 'akihito',\n",
       " 'alabadi',\n",
       " 'alarmed',\n",
       " 'alassad',\n",
       " 'albanian',\n",
       " 'alberto',\n",
       " 'albu',\n",
       " 'album',\n",
       " 'albums',\n",
       " 'alchemy',\n",
       " 'alcom',\n",
       " 'aldean',\n",
       " 'alec',\n",
       " 'alejandro',\n",
       " 'aleppo',\n",
       " 'alex',\n",
       " 'alexander',\n",
       " 'alexandras',\n",
       " 'alghero',\n",
       " 'algorithm',\n",
       " 'alhariri',\n",
       " 'ali',\n",
       " 'alien',\n",
       " 'alienating',\n",
       " 'aliens',\n",
       " 'alik',\n",
       " 'alinsky',\n",
       " 'aliranger',\n",
       " 'alis',\n",
       " 'alist',\n",
       " 'alito',\n",
       " 'alkaline',\n",
       " 'allay',\n",
       " 'alle',\n",
       " 'allegation',\n",
       " 'allegations',\n",
       " 'allegedly',\n",
       " 'alleges',\n",
       " 'allergan',\n",
       " 'alles',\n",
       " 'allfeatured',\n",
       " 'alliance',\n",
       " 'alliances',\n",
       " 'allied',\n",
       " 'allies',\n",
       " 'allout',\n",
       " 'allowing',\n",
       " 'ally',\n",
       " 'alnusra',\n",
       " 'aloud',\n",
       " 'alphabet',\n",
       " 'alps',\n",
       " 'alptekin',\n",
       " 'alqaeda',\n",
       " 'alqaim',\n",
       " 'alquds',\n",
       " 'alright',\n",
       " 'als',\n",
       " 'alshaabi',\n",
       " 'alsisi',\n",
       " 'alt',\n",
       " 'altdept',\n",
       " 'alternate',\n",
       " 'alternet',\n",
       " 'althani',\n",
       " 'altinterior',\n",
       " 'altitude',\n",
       " 'altleft',\n",
       " 'altmaier',\n",
       " 'altright',\n",
       " 'alzor',\n",
       " 'ama',\n",
       " 'amaal',\n",
       " 'amanat',\n",
       " 'amano',\n",
       " 'amaq',\n",
       " 'amateur',\n",
       " 'amazing',\n",
       " 'amazingly',\n",
       " 'amazon',\n",
       " 'amazons',\n",
       " 'ambassador',\n",
       " 'ambassadors',\n",
       " 'amber',\n",
       " 'ambition',\n",
       " 'ambitions',\n",
       " 'ambitious',\n",
       " 'ambulances',\n",
       " 'amend',\n",
       " 'amended',\n",
       " 'amending',\n",
       " 'amendment',\n",
       " 'amendments',\n",
       " 'america',\n",
       " 'americafeatured',\n",
       " 'american',\n",
       " 'americans',\n",
       " 'americas',\n",
       " 'amerika',\n",
       " 'amiri',\n",
       " 'amman',\n",
       " 'ammo',\n",
       " 'ammon',\n",
       " 'ammonium',\n",
       " 'amnesty',\n",
       " 'amona',\n",
       " 'amri',\n",
       " 'amsterdam',\n",
       " 'amtrak',\n",
       " 'amtv',\n",
       " 'amused',\n",
       " 'amusements',\n",
       " 'anadolu',\n",
       " 'anakin',\n",
       " 'analogy',\n",
       " 'analyses',\n",
       " 'analyst',\n",
       " 'analysts',\n",
       " 'analytics',\n",
       " 'anbang',\n",
       " 'anc',\n",
       " 'ancient',\n",
       " 'andere',\n",
       " 'anderen',\n",
       " 'anderson',\n",
       " 'andor',\n",
       " 'andrej',\n",
       " 'andres',\n",
       " 'andrew',\n",
       " 'android',\n",
       " 'angela',\n",
       " 'angeles',\n",
       " 'angered',\n",
       " 'angerer',\n",
       " 'angerergetty',\n",
       " 'angering',\n",
       " 'angola',\n",
       " 'angry',\n",
       " 'animals',\n",
       " 'animated',\n",
       " 'anis',\n",
       " 'ankara',\n",
       " 'anncoulter',\n",
       " 'annexation',\n",
       " 'annexed',\n",
       " 'anniversary',\n",
       " 'announced',\n",
       " 'announcement',\n",
       " 'announcements',\n",
       " 'announces',\n",
       " 'announcing',\n",
       " 'annual',\n",
       " 'annually',\n",
       " 'annulled',\n",
       " 'annulment',\n",
       " 'ano',\n",
       " 'anonymity',\n",
       " 'anonymous',\n",
       " 'ans',\n",
       " 'ansari',\n",
       " 'answer',\n",
       " 'antes',\n",
       " 'anthem',\n",
       " 'anthony',\n",
       " 'anti',\n",
       " 'antiamerican',\n",
       " 'antibacterial',\n",
       " 'antiblack',\n",
       " 'antichoice',\n",
       " 'antichrist',\n",
       " 'antichristian',\n",
       " 'anticipated',\n",
       " 'anticop',\n",
       " 'anticorruption',\n",
       " 'antics',\n",
       " 'antidoping',\n",
       " 'antidrug',\n",
       " 'antidumping',\n",
       " 'antieu',\n",
       " 'antifa',\n",
       " 'antifungal',\n",
       " 'antigay',\n",
       " 'antigraft',\n",
       " 'antigun',\n",
       " 'antihillary',\n",
       " 'antiinflammatory',\n",
       " 'antilgbt',\n",
       " 'antimedia',\n",
       " 'antimissile',\n",
       " 'antimoney',\n",
       " 'antimuslim',\n",
       " 'antiobama',\n",
       " 'antioxidant',\n",
       " 'antioxidants',\n",
       " 'antipolice',\n",
       " 'antirussian',\n",
       " 'antisemite',\n",
       " 'antisemitic',\n",
       " 'antitrump',\n",
       " 'antitrust',\n",
       " 'antiwar',\n",
       " 'antiwhite',\n",
       " 'antiwoman',\n",
       " 'antonin',\n",
       " 'antonio',\n",
       " 'antonov',\n",
       " 'anwr',\n",
       " 'aoltimewarner',\n",
       " 'aos',\n",
       " 'aoun',\n",
       " 'ap',\n",
       " 'apartment',\n",
       " 'apartments',\n",
       " 'apec',\n",
       " 'apocalypse',\n",
       " 'apologists',\n",
       " 'apologize',\n",
       " 'app',\n",
       " 'appalling',\n",
       " 'appeal',\n",
       " 'appealed',\n",
       " 'appeals',\n",
       " 'appeared',\n",
       " 'appears',\n",
       " 'appellate',\n",
       " 'appetite',\n",
       " 'applauded',\n",
       " 'applause',\n",
       " 'apple',\n",
       " 'applicants',\n",
       " 'application',\n",
       " 'applications',\n",
       " 'apply',\n",
       " 'appointed',\n",
       " 'appointment',\n",
       " 'appraisal',\n",
       " 'approach',\n",
       " 'appropriations',\n",
       " 'approval',\n",
       " 'approve',\n",
       " 'approved',\n",
       " 'approves',\n",
       " 'approving',\n",
       " 'apps',\n",
       " 'april',\n",
       " 'ara',\n",
       " 'arab',\n",
       " 'arabia',\n",
       " 'arabic',\n",
       " 'arafat',\n",
       " 'arakan',\n",
       " 'araoz',\n",
       " 'arbitration',\n",
       " 'arbitrator',\n",
       " 'archaeological',\n",
       " 'archdiocese',\n",
       " 'archfoe',\n",
       " 'archuleta',\n",
       " 'arctic',\n",
       " 'ardern',\n",
       " 'arduous',\n",
       " 'argentina',\n",
       " 'argentine',\n",
       " 'argentines',\n",
       " 'argued',\n",
       " 'arguing',\n",
       " 'arguments',\n",
       " 'arizonas',\n",
       " 'ark',\n",
       " 'armageddon',\n",
       " 'armed',\n",
       " 'armes',\n",
       " 'armi',\n",
       " 'armour',\n",
       " 'armstrong',\n",
       " 'army',\n",
       " 'arnaldo',\n",
       " 'arnoldski',\n",
       " 'arora',\n",
       " 'arpaio',\n",
       " 'arrangement',\n",
       " 'array',\n",
       " 'arrest',\n",
       " 'arrested',\n",
       " 'arrests',\n",
       " 'arrival',\n",
       " 'arrivals',\n",
       " 'arrive',\n",
       " 'arrived',\n",
       " 'arrives',\n",
       " 'arriving',\n",
       " 'arrogant',\n",
       " 'arrogantly',\n",
       " 'arrows',\n",
       " 'arsa',\n",
       " 'arson',\n",
       " 'art',\n",
       " 'arteries',\n",
       " 'arthur',\n",
       " 'article',\n",
       " 'articles',\n",
       " 'artikel',\n",
       " 'artiles',\n",
       " 'artists',\n",
       " 'arya',\n",
       " 'aryan',\n",
       " 'asap',\n",
       " 'asean',\n",
       " 'ashamed',\n",
       " 'ashlee',\n",
       " 'ashore',\n",
       " 'ashraf',\n",
       " 'asia',\n",
       " 'asiabriefingnytimes',\n",
       " 'asian',\n",
       " 'asiapacific',\n",
       " 'asinine',\n",
       " 'aska',\n",
       " 'aslan',\n",
       " 'aso',\n",
       " 'aspartame',\n",
       " 'aspect',\n",
       " 'aspirational',\n",
       " 'asplund',\n",
       " 'ass',\n",
       " 'assad',\n",
       " 'assads',\n",
       " 'assail',\n",
       " 'assailant',\n",
       " 'assailants',\n",
       " 'assailed',\n",
       " 'assange',\n",
       " 'assanges',\n",
       " 'assassinated',\n",
       " 'assault',\n",
       " 'assaulted',\n",
       " 'assaulter',\n",
       " 'assaulting',\n",
       " 'assemblies',\n",
       " 'assembling',\n",
       " 'assembly',\n",
       " 'assessment',\n",
       " 'assessments',\n",
       " 'assets',\n",
       " 'asshole',\n",
       " 'assholes',\n",
       " 'assigns',\n",
       " 'assimilating',\n",
       " 'assistance',\n",
       " 'assistant',\n",
       " 'assists',\n",
       " 'associate',\n",
       " 'associates',\n",
       " 'association',\n",
       " 'associations',\n",
       " 'assorted',\n",
       " 'assume',\n",
       " 'assurances',\n",
       " 'astana',\n",
       " 'asterisk',\n",
       " 'asteroids',\n",
       " 'astonishing',\n",
       " 'astounding',\n",
       " 'astrazeneca',\n",
       " 'astronomical',\n",
       " 'astronomy',\n",
       " 'asuntos',\n",
       " 'asylum',\n",
       " 'asylumseekers',\n",
       " 'ata',\n",
       " 'atheists',\n",
       " 'athens',\n",
       " 'athletes',\n",
       " 'atilla',\n",
       " 'atlanta',\n",
       " 'atlantas',\n",
       " 'atlantic',\n",
       " 'atomic',\n",
       " 'atrium',\n",
       " 'att',\n",
       " 'attachment',\n",
       " 'attack',\n",
       " 'attackers',\n",
       " 'attacking',\n",
       " 'attacks',\n",
       " 'attempted',\n",
       " 'attempting',\n",
       " 'attend',\n",
       " 'attended',\n",
       " 'attorneys',\n",
       " 'attract',\n",
       " 'attracting',\n",
       " 'attribution',\n",
       " 'atty',\n",
       " 'atzmon',\n",
       " 'auch',\n",
       " 'auckland',\n",
       " 'auction',\n",
       " 'audacity',\n",
       " 'audi',\n",
       " 'audiences',\n",
       " 'audio',\n",
       " 'auf',\n",
       " 'aufc',\n",
       " 'aug',\n",
       " 'august',\n",
       " 'aung',\n",
       " 'auriemma',\n",
       " 'aus',\n",
       " 'auschwitz',\n",
       " 'aussi',\n",
       " 'austere',\n",
       " 'austerity',\n",
       " 'austin',\n",
       " 'australia',\n",
       " 'australian',\n",
       " 'austria',\n",
       " 'austrias',\n",
       " 'author',\n",
       " 'authorities',\n",
       " 'authority',\n",
       " 'authorization',\n",
       " 'authorize',\n",
       " 'authorized',\n",
       " 'authorizing',\n",
       " 'autism',\n",
       " 'auto',\n",
       " 'autoliv',\n",
       " 'automaker',\n",
       " 'automakers',\n",
       " 'automation',\n",
       " 'automotive',\n",
       " 'autonomous',\n",
       " 'autonomy',\n",
       " 'autopilot',\n",
       " 'autres',\n",
       " 'aux',\n",
       " 'avaaz',\n",
       " 'avec',\n",
       " 'avenue',\n",
       " 'avenues',\n",
       " 'average',\n",
       " 'averaging',\n",
       " 'avert',\n",
       " 'aviation',\n",
       " 'aviv',\n",
       " 'avoid',\n",
       " 'avoided',\n",
       " 'awaiting',\n",
       " 'awakening',\n",
       " 'awan',\n",
       " 'awarded',\n",
       " 'awards',\n",
       " 'awardwinning',\n",
       " 'awareness',\n",
       " 'awesome',\n",
       " 'awful',\n",
       " 'awhile',\n",
       " 'awr',\n",
       " 'awrhawkins',\n",
       " 'awrhawkinsbreitbart',\n",
       " 'axios',\n",
       " 'axis',\n",
       " 'ayatollah',\n",
       " 'ayn',\n",
       " 'ayotte',\n",
       " 'ayrault',\n",
       " 'ayres',\n",
       " 'azar',\n",
       " 'azaria',\n",
       " 'aziz',\n",
       " 'bab',\n",
       " 'babin',\n",
       " 'babis',\n",
       " 'bachelet',\n",
       " 'bachelors',\n",
       " 'backdrop',\n",
       " 'backer',\n",
       " 'backers',\n",
       " 'backlog',\n",
       " 'bad',\n",
       " 'badass',\n",
       " 'baffling',\n",
       " 'bagel',\n",
       " 'baghdad',\n",
       " 'bahrain',\n",
       " 'baier',\n",
       " 'baio',\n",
       " 'bake',\n",
       " 'baker',\n",
       " 'baking',\n",
       " 'bakraoui',\n",
       " 'balance',\n",
       " 'balanced',\n",
       " 'balbi',\n",
       " 'balcony',\n",
       " 'baldas',\n",
       " 'baldasaro',\n",
       " 'baldwins',\n",
       " 'bali',\n",
       " 'balkan',\n",
       " 'balkans',\n",
       " 'balked',\n",
       " 'ballet',\n",
       " 'ballistic',\n",
       " 'balloon',\n",
       " 'ballot',\n",
       " 'ballots',\n",
       " 'ban',\n",
       " 'banana',\n",
       " 'bangkok',\n",
       " 'bangladesh',\n",
       " 'bangladeshi',\n",
       " 'bani',\n",
       " 'bank',\n",
       " 'banker',\n",
       " 'bankrupt',\n",
       " 'bankruptcy',\n",
       " 'banks',\n",
       " 'banksters',\n",
       " 'banned',\n",
       " 'bannock',\n",
       " 'bannon',\n",
       " 'bannons',\n",
       " 'bans',\n",
       " 'bao',\n",
       " 'bar',\n",
       " 'barack',\n",
       " 'barackobama',\n",
       " 'baraka',\n",
       " 'barakat',\n",
       " 'barbie',\n",
       " 'barbs',\n",
       " 'barcelona',\n",
       " 'barclays',\n",
       " 'barfly',\n",
       " 'bargain',\n",
       " 'bargaining',\n",
       " 'barghouti',\n",
       " 'barnier',\n",
       " 'baroni',\n",
       " 'barrasso',\n",
       " 'barred',\n",
       " 'barrels',\n",
       " 'barrier',\n",
       " 'barriers',\n",
       " 'barring',\n",
       " 'bars',\n",
       " 'barzani',\n",
       " 'base',\n",
       " 'baseballs',\n",
       " 'based',\n",
       " 'bash',\n",
       " 'bashar',\n",
       " 'bashes',\n",
       " 'bashing',\n",
       " 'bashir',\n",
       " 'basically',\n",
       " 'basketball',\n",
       " 'basque',\n",
       " 'bass',\n",
       " 'bastard',\n",
       " 'batista',\n",
       " 'baton',\n",
       " 'battalion',\n",
       " 'battered',\n",
       " 'batteries',\n",
       " 'battista',\n",
       " 'battle',\n",
       " 'battled',\n",
       " 'battlegrounds',\n",
       " 'battles',\n",
       " 'battling',\n",
       " 'baudrillard',\n",
       " 'bavaria',\n",
       " 'bavarian',\n",
       " 'baxter',\n",
       " 'bay',\n",
       " 'bayer',\n",
       " 'bayh',\n",
       " 'bazar',\n",
       " 'bc',\n",
       " 'bds',\n",
       " 'beach',\n",
       " 'beaches',\n",
       " 'beacon',\n",
       " 'beans',\n",
       " 'bears',\n",
       " 'beasts',\n",
       " 'beaten',\n",
       " 'beautiful',\n",
       " 'becerra',\n",
       " 'beck',\n",
       " 'bee',\n",
       " 'beeley',\n",
       " 'bees',\n",
       " 'beg',\n",
       " 'begging',\n",
       " 'begs',\n",
       " 'begun',\n",
       " 'behar',\n",
       " 'behavior',\n",
       " 'behaviour',\n",
       " 'bei',\n",
       " 'beijing',\n",
       " 'beijings',\n",
       " 'beirut',\n",
       " 'beit',\n",
       " 'belgian',\n",
       " 'belgium',\n",
       " 'belgrade',\n",
       " 'belichick',\n",
       " 'beliefs',\n",
       " 'believed',\n",
       " 'believes',\n",
       " 'believing',\n",
       " 'bella',\n",
       " 'bellamy',\n",
       " 'belle',\n",
       " 'bellicose',\n",
       " 'bello',\n",
       " 'belowfeatured',\n",
       " 'belowthe',\n",
       " 'belt',\n",
       " 'beltran',\n",
       " 'bench',\n",
       " 'benchmark',\n",
       " 'benchmarks',\n",
       " 'benediktsson',\n",
       " 'beneficiary',\n",
       " 'benefits',\n",
       " 'bengal',\n",
       " 'benghazi',\n",
       " 'benioff',\n",
       " 'benjamin',\n",
       " 'benkew',\n",
       " 'bennell',\n",
       " 'bennet',\n",
       " 'bensasse',\n",
       " 'bentley',\n",
       " 'bentz',\n",
       " 'ber',\n",
       " 'berenstain',\n",
       " 'bergquist',\n",
       " 'berkshire',\n",
       " 'berlin',\n",
       " 'berlusconi',\n",
       " 'bern',\n",
       " 'bernie',\n",
       " 'bernish',\n",
       " 'beset',\n",
       " 'beshear',\n",
       " 'besieged',\n",
       " 'bess',\n",
       " 'bessbell',\n",
       " 'bestknown',\n",
       " 'bet',\n",
       " 'beth',\n",
       " 'bets',\n",
       " 'betting',\n",
       " 'bev',\n",
       " 'beyonce',\n",
       " 'beyoncs',\n",
       " 'bff',\n",
       " 'bharara',\n",
       " 'bhararas',\n",
       " 'bhumibol',\n",
       " 'bias',\n",
       " 'bible',\n",
       " 'bid',\n",
       " 'biden',\n",
       " 'bids',\n",
       " 'bien',\n",
       " 'biggest',\n",
       " 'bigly',\n",
       " 'bigmoney',\n",
       " 'bigot',\n",
       " 'bigoted',\n",
       " 'bigotry',\n",
       " 'bigots',\n",
       " 'bikers',\n",
       " 'bilateral',\n",
       " 'bild',\n",
       " 'bilden',\n",
       " 'bilderberg',\n",
       " 'biles',\n",
       " 'billionaire',\n",
       " 'bills',\n",
       " 'bin',\n",
       " 'binali',\n",
       " 'binder',\n",
       " 'binding',\n",
       " 'binney',\n",
       " 'bio',\n",
       " 'biofuels',\n",
       " 'biologist',\n",
       " 'bipartisan',\n",
       " 'bir',\n",
       " 'bird',\n",
       " 'birdie',\n",
       " 'birds',\n",
       " 'birth',\n",
       " 'birther',\n",
       " 'birthers',\n",
       " 'bis',\n",
       " 'bisexual',\n",
       " 'bison',\n",
       " 'bit',\n",
       " 'bitch',\n",
       " 'bitches',\n",
       " 'bitlyjbhlu',\n",
       " 'bitlyjpexyr',\n",
       " 'bitterly',\n",
       " 'bizarre',\n",
       " 'bjp',\n",
       " 'bkewbreitbart',\n",
       " 'black',\n",
       " 'blackburn',\n",
       " 'blackheads',\n",
       " 'blacklist',\n",
       " 'blacklivesmatter',\n",
       " 'blackonblack',\n",
       " 'blacks',\n",
       " 'blah',\n",
       " 'blame',\n",
       " 'blamed',\n",
       " 'blaming',\n",
       " 'blared',\n",
       " 'blasio',\n",
       " 'blasios',\n",
       " 'blasphemy',\n",
       " 'blast',\n",
       " 'blasted',\n",
       " 'blatant',\n",
       " 'blatantly',\n",
       " 'bleachbit',\n",
       " 'blend',\n",
       " 'blending',\n",
       " 'blessing',\n",
       " 'blitz',\n",
       " 'blitzer',\n",
       " 'blizzard',\n",
       " 'blm',\n",
       " 'bloc',\n",
       " 'block',\n",
       " 'blockade',\n",
       " 'blocked',\n",
       " 'blocking',\n",
       " 'blockquotea',\n",
       " 'blocks',\n",
       " 'blocs',\n",
       " 'blog',\n",
       " 'blogspot',\n",
       " 'blooms',\n",
       " 'bloqueo',\n",
       " 'blowhard',\n",
       " 'blueprint',\n",
       " 'blues',\n",
       " 'bmw',\n",
       " 'bni',\n",
       " 'boakai',\n",
       " 'board',\n",
       " 'boarding',\n",
       " 'boards',\n",
       " 'boat',\n",
       " 'boats',\n",
       " 'boaty',\n",
       " 'bob',\n",
       " 'bobpricebbtx',\n",
       " ...]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "54a05eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_lst10000=sw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02f3e46",
   "metadata": {},
   "source": [
    "## 2) textcuboid 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1fcda7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_lst=[]\n",
    "for sen in x_train:\n",
    "    doc_lst.append(sen.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8219b3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lst=[]\n",
    "for sen in x_test:\n",
    "    test_lst.append(sen.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00fdd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train_data에서 문서가 갖고 있는 선별한 feauture의 수 확인\n",
    "count_lst=[]\n",
    "for i in range(16000):\n",
    "    total_feature_cnt=0\n",
    "    for j in range(10000):\n",
    "        if feature_lst10000[j] in doc_lst[i]:\n",
    "            total_feature_cnt+=1\n",
    "    count_lst.append(total_feature_cnt)\n",
    "    \n",
    "print('Train_data에서 가장 많은 feature를 가진 문서의 경우 feature',max(count_lst),' 개를 가짐')\n",
    "print('Train_data에서 가장 적은 feature를 가진 문서의 경우 feature',min(count_lst),' 개를 가짐')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986eda6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test_data에서 문서가 갖고 있는 선별한 feauture의 수 확인\n",
    "count_lst=[]\n",
    "for i in range(4000):\n",
    "    \n",
    "    total_feature_cnt=0\n",
    "    for j in range(10000):\n",
    "        if feature_lst10000[j] in test_lst[i]:\n",
    "            total_feature_cnt+=1\n",
    "    count_lst.append(total_feature_cnt)\n",
    "    \n",
    "print('Test_data에서 가장 많은 feature를 가진 문서의 경우 feature',max(count_lst),' 개를 가짐')\n",
    "print('Test_data에서 가장 적은 feature를 가진 문서의 경우 feature',min(count_lst),' 개를 가짐')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cc35ecbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1-Channel TextCuboid 생성\n",
    "textcuboid=[]\n",
    "if cnt>-1:  #cross vaidation을 위한 2번째 이후의 시행인 경우\n",
    "    for i in train_idx:\n",
    "        frame1=np.zeros((391,256))  #(maximum number of features, 256)\n",
    "        idx_cnt=0\n",
    "        for j in range(10000):\n",
    "            if feature_lst10000[j] in doc_lst[i]:\n",
    "                #문서에서 선별한 단어(feature)의 위치를 찾아 임베딩 벡터 추출\n",
    "                frame1[idx_cnt]=np.load('C:/Users/user/Desktop/Multimodal TextCuboid/WELFake 분류/elmo_embedding/train(WELFake256)/doc%d.npy'%i)[doc_lst[i].index(feature_lst10000[j])]\n",
    "                idx_cnt+=1\n",
    "        textcuboid.append(frame1)  #train data의 일부 문서에 대한 TexrCuboid가 추가됨\n",
    "        \n",
    "    for i in range(4000):\n",
    "        frame1=np.zeros((391,256))  #(maximum number of features, 256)\n",
    "        idx_cnt=0\n",
    "        for j in range(10000):\n",
    "            if feature_lst10000[j] in test_lst[i]:\n",
    "                #문서에서 선별한 단어(feature)의 위치를 찾아 임베딩 벡터 추출\n",
    "                frame1[idx_cnt]=np.load('C:/Users/user/Desktop/Multimodal TextCuboid/WELFake 분류/elmo_embedding/test(WELFake256)/test%d.npy'%i)[test_lst[i].index(feature_lst10000[j])]\n",
    "                idx_cnt+=1\n",
    "        textcuboid.append(frame1)  #test data의 문서에 대한 TexrCuboid가 추가됨\n",
    "        \n",
    "\n",
    "    textcuboid=np.array(textcuboid)\n",
    "\n",
    "    np.save('./1-Channel textcuboid_WELFake(elmo).npy',textcuboid)   \n",
    "    \n",
    "else:   #첫번째 시행인 경우\n",
    "    for i in range(16000): \n",
    "        frame1=np.zeros((391,256))  #(maximum number of features, 256)\n",
    "        idx_cnt=0\n",
    "        for j in range(10000):\n",
    "            if feature_lst10000[j] in doc_lst[i]:\n",
    "                #문서에서 선별한 단어(feature)의 위치를 찾아 임베딩 벡터 추출\n",
    "                frame1[idx_cnt]=np.load('C:/Users/user/Desktop/Multimodal TextCuboid/WELFake 분류/elmo_embedding/train(WELFake256)/doc%d.npy'%i)[doc_lst[i].index(feature_lst10000[j])]\n",
    "                idx_cnt+=1\n",
    "        textcuboid.append(frame1)\n",
    "\n",
    "    textcuboid=np.array(textcuboid)\n",
    "\n",
    "    np.save('./1-Channel textcuboid_WELFake(elmo).npy',textcuboid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a3071295",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1-Channel TextCuboid 생성\n",
    "textcuboid_test=[]\n",
    "\n",
    "if cnt>-1:\n",
    "    for i in test_idx:\n",
    "        frame1=np.zeros((391,256))    #(maximum number of features, 256)\n",
    "        idx_cnt=0\n",
    "        for j in range(10000):\n",
    "            if feature_lst10000[j] in doc_lst[i]:\n",
    "                #문서에서 선별한 단어(feature)의 위치를 찾아 임베딩 벡터 추출\n",
    "                frame1[idx_cnt]=np.load('C:/Users/user/Desktop/Multimodal TextCuboid/WELFake 분류/elmo_embedding/train(WELFake256)/doc%d.npy'%i)[doc_lst[i].index(feature_lst10000[j])]\n",
    "                idx_cnt+=1\n",
    "        textcuboid_test.append(frame1)\n",
    "        \n",
    "    textcuboid_test=np.array(textcuboid_test)\n",
    "    np.save('./1-Channel textcuboid_test_WELFake(elmo).npy',textcuboid_test)\n",
    "    \n",
    "else:\n",
    "    for i in range(4000):\n",
    "        frame1=np.zeros((391,256))    #(maximum number of features, 256)\n",
    "        idx_cnt=0\n",
    "        for j in range(10000):\n",
    "            if feature_lst10000[j] in test_lst[i]:\n",
    "                #문서에서 선별한 단어(feature)의 위치를 찾아 임베딩 벡터 추출\n",
    "                frame1[idx_cnt]=np.load('C:/Users/user/Desktop/Multimodal TextCuboid/WELFake 분류/elmo_embedding/test(WELFake256)/test%d.npy'%i)[test_lst[i].index(feature_lst10000[j])]\n",
    "                idx_cnt+=1\n",
    "        textcuboid_test.append(frame1)\n",
    "\n",
    "    textcuboid_test=np.array(textcuboid_test)\n",
    "    np.save('./1-Channel textcuboid_test_WELFake(elmo).npy',textcuboid_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760adb71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
