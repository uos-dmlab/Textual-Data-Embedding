{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "184f59ff",
   "metadata": {},
   "source": [
    "# Textcuboid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "849c1414",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import nltk\n",
    "import re\n",
    "import string\n",
    "import json\n",
    "import keras\n",
    "import wordninja\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c372e2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:/Users/user/Desktop/bilm-tf-master/textdataset/WELFake/WELFake_Dataset.csv')\n",
    "\n",
    "df = df.dropna()\n",
    "df.isnull().sum()\n",
    "\n",
    "df.drop(columns=['Unnamed: 0'],inplace=True)\n",
    "\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "X = df.drop(columns=['label'])\n",
    "y = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f185c938",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    punctuationfree=\"\".join([i for i in text if i not in string.punctuation])\n",
    "    return punctuationfree\n",
    "\n",
    "X[['title','text']] = X[['title','text']].applymap(lambda x:remove_punctuation(x))\n",
    "X[['title','text']] = X[['title','text']].applymap(lambda x:x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe6af472",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text=str(text).lower() #Converts text to lowercase\n",
    "    text=re.sub('\\d+', '', text) #removes numbers\n",
    "    text=re.sub('\\[.*?\\]', '', text) #removes HTML tags\n",
    "    text=re.sub('https?://\\S+|www\\.\\S+', '', text) #removes url\n",
    "    text=re.sub(r\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", \"\", text) #removes emojis\n",
    "    text=re.sub('[%s]' % re.escape(string.punctuation),'',text) #removes punctuations\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10980a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X['title']+' '+X['text']\n",
    "\n",
    "X = X.apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "174e499d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = list(X)\n",
    "\n",
    "pattern = '[^a-z ]'\n",
    "Clean_X=[]\n",
    "for sen in X:\n",
    "    Clean_X.append(re.sub(pattern, '', str(sen)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eaa2ae88",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = pd.DataFrame({'Clean_X': Clean_X, 'y': y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a463bf21",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_df = clean_df[clean_df['y'] == 0]\n",
    "real_df = clean_df[clean_df['y'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "236c87ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_x=list(fake_df['Clean_X'])\n",
    "real_x=list(real_df['Clean_X'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd144a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_selected_lst = []\n",
    "fake_selected_lst = []\n",
    "\n",
    "for sen in real_x:\n",
    "    word_count = len(sen.split())\n",
    "    if 10 <= word_count < 2000:\n",
    "        real_selected_lst.append(sen)\n",
    "        \n",
    "for sen in fake_x:\n",
    "    word_count = len(sen.split())\n",
    "    if 10 <= word_count < 2000:\n",
    "        fake_selected_lst.append(sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4ada5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=real_selected_lst[:10000]+fake_selected_lst[:10000]\n",
    "y=[0]*10000+[1]*10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30619af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ac2d5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_txt=x_train+x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0285619",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_compound_words(text):\n",
    "    return ' '.join(wordninja.split(text))\n",
    "\n",
    "to_txt_split=[]\n",
    "for i in to_txt:\n",
    "    to_txt_split.append(split_compound_words(i))\n",
    "\n",
    "to_txt=to_txt_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5c372fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#문서 길이를 조정하는 코드 텍스트 리스트와 최대 길이를 입력하면 단어 시퀀스를 최대 길이 이내로 truncate 해줌\n",
    "def limit_words(text_list, max_words):\n",
    "    new_list = []\n",
    "    for text in text_list:\n",
    "        words = text.split()\n",
    "        if len(words) > max_words:\n",
    "            words = words[:max_words]\n",
    "        new_text = ' '.join(words)\n",
    "        new_list.append(new_text)\n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb9196ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#사전학습된 버트는 최대 임베딩 토큰 수(512)가 정해져 있으므로 넉넉하게 최대길이를 300으로 제한\n",
    "to_txt=limit_words(to_txt,300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "578d0260",
   "metadata": {},
   "outputs": [],
   "source": [
    "#수동으로 cross validation을 하기위한 코드\n",
    "cnt=5  #cnt가 2일때 두번째 시행\n",
    "cnt=cnt-2\n",
    "\n",
    "#텍스트 큐보이드 생성을 위한 인덱스\n",
    "def train_idx_list(cnt):\n",
    "    original_train_lst=[i for i in range(16000)]\n",
    "    return original_train_lst[:cnt*4000]+original_train_lst[cnt*4000+4000:16000]\n",
    "\n",
    "def test_idx_list(cnt):\n",
    "    original_train_lst=[i for i in range(16000)]\n",
    "    return original_train_lst[cnt*4000:cnt*4000+4000]\n",
    "    \n",
    "if cnt>-1:\n",
    "    train_idx=train_idx_list(cnt)\n",
    "    test_idx=test_idx_list(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "39504c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#불용어 불러오기\n",
    "with open('C:/Users/user/Desktop/english.txt', 'r', encoding='utf-8') as file:\n",
    "    stopwords = [line.strip() for line in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b8c0c41a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'daren', 'hadn', 'herse', 'himse', 'itse', 'mayn', 'mightn', 'mon', 'mustn', 'myse', 'needn', 'oughtn', 'shan'] not in stop_words.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer(stop_words=stopwords)\n",
    "X_dtm = vect.fit_transform(to_txt)\n",
    "X_dtm = X_dtm.toarray()\n",
    "X_new = SelectKBest(chi2, k=10000).fit(X_dtm, y)\n",
    "TorF = X_new.get_support()\n",
    "TorF\n",
    "import numpy as np\n",
    "word_view=np.array(vect.get_feature_names())\n",
    "sw=word_view[TorF]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c530d167",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aaaa',\n",
       " 'aaf',\n",
       " 'aap',\n",
       " 'aardvark',\n",
       " 'ab',\n",
       " 'abandons',\n",
       " 'abated',\n",
       " 'abba',\n",
       " 'abbas',\n",
       " 'abbasi',\n",
       " 'abbott',\n",
       " 'abbottabad',\n",
       " 'abd',\n",
       " 'abdullah',\n",
       " 'abel',\n",
       " 'abell',\n",
       " 'abella',\n",
       " 'abercrombie',\n",
       " 'aberdeen',\n",
       " 'aberration',\n",
       " 'abhor',\n",
       " 'abhorrent',\n",
       " 'abid',\n",
       " 'abidin',\n",
       " 'ablaze',\n",
       " 'abolished',\n",
       " 'aboriginal',\n",
       " 'abortion',\n",
       " 'abortive',\n",
       " 'abou',\n",
       " 'abra',\n",
       " 'abraham',\n",
       " 'absences',\n",
       " 'absentia',\n",
       " 'absolute',\n",
       " 'absorb',\n",
       " 'abstaining',\n",
       " 'abstentions',\n",
       " 'absurd',\n",
       " 'absurdity',\n",
       " 'abu',\n",
       " 'abuja',\n",
       " 'abundance',\n",
       " 'abuse',\n",
       " 'abuses',\n",
       " 'academia',\n",
       " 'academics',\n",
       " 'academies',\n",
       " 'acadia',\n",
       " 'accelerate',\n",
       " 'accident',\n",
       " 'acclaim',\n",
       " 'acclaimed',\n",
       " 'acclamation',\n",
       " 'accommodating',\n",
       " 'accommodations',\n",
       " 'accompaniment',\n",
       " 'accomplishment',\n",
       " 'accomplishments',\n",
       " 'accord',\n",
       " 'account',\n",
       " 'accumulate',\n",
       " 'accumulating',\n",
       " 'accurate',\n",
       " 'accurately',\n",
       " 'accusations',\n",
       " 'accuser',\n",
       " 'accusers',\n",
       " 'accuses',\n",
       " 'acerbic',\n",
       " 'acetate',\n",
       " 'acheron',\n",
       " 'achi',\n",
       " 'achieve',\n",
       " 'achilles',\n",
       " 'acht',\n",
       " 'acid',\n",
       " 'acidic',\n",
       " 'acker',\n",
       " 'acknowledgement',\n",
       " 'aclu',\n",
       " 'acosta',\n",
       " 'acquaintance',\n",
       " 'acquire',\n",
       " 'acquittals',\n",
       " 'acquitted',\n",
       " 'acreage',\n",
       " 'acres',\n",
       " 'acrimonious',\n",
       " 'acted',\n",
       " 'actions',\n",
       " 'activation',\n",
       " 'activision',\n",
       " 'activist',\n",
       " 'activists',\n",
       " 'actor',\n",
       " 'actuality',\n",
       " 'actuarial',\n",
       " 'actuary',\n",
       " 'acupuncture',\n",
       " 'adam',\n",
       " 'adams',\n",
       " 'adder',\n",
       " 'addict',\n",
       " 'addicts',\n",
       " 'addressed',\n",
       " 'adelaide',\n",
       " 'adele',\n",
       " 'aden',\n",
       " 'adept',\n",
       " 'adequate',\n",
       " 'adh',\n",
       " 'adhere',\n",
       " 'adhered',\n",
       " 'adige',\n",
       " 'adirondack',\n",
       " 'adjective',\n",
       " 'adjourned',\n",
       " 'adjustment',\n",
       " 'adkins',\n",
       " 'admin',\n",
       " 'administration',\n",
       " 'administrations',\n",
       " 'administrator',\n",
       " 'admiral',\n",
       " 'admiralty',\n",
       " 'admits',\n",
       " 'adult',\n",
       " 'adulterous',\n",
       " 'adultery',\n",
       " 'adults',\n",
       " 'adventist',\n",
       " 'adventures',\n",
       " 'adversary',\n",
       " 'advert',\n",
       " 'advertisement',\n",
       " 'adviser',\n",
       " 'adze',\n",
       " 'aedes',\n",
       " 'aeon',\n",
       " 'aer',\n",
       " 'aerobics',\n",
       " 'aerodynamic',\n",
       " 'aerosmith',\n",
       " 'affiliated',\n",
       " 'affirmation',\n",
       " 'affirmed',\n",
       " 'affirms',\n",
       " 'affleck',\n",
       " 'afflicted',\n",
       " 'afflicting',\n",
       " 'affordable',\n",
       " 'afghan',\n",
       " 'afghanistan',\n",
       " 'afghans',\n",
       " 'afk',\n",
       " 'afl',\n",
       " 'aflame',\n",
       " 'afr',\n",
       " 'aft',\n",
       " 'afterlife',\n",
       " 'afternoon',\n",
       " 'aftershocks',\n",
       " 'afterward',\n",
       " 'agencies',\n",
       " 'agents',\n",
       " 'aggregate',\n",
       " 'aggressively',\n",
       " 'agha',\n",
       " 'agile',\n",
       " 'agitated',\n",
       " 'agli',\n",
       " 'agn',\n",
       " 'agnes',\n",
       " 'agreement',\n",
       " 'agriculture',\n",
       " 'aguilera',\n",
       " 'aha',\n",
       " 'ahal',\n",
       " 'ahl',\n",
       " 'ahmadi',\n",
       " 'ahmet',\n",
       " 'aide',\n",
       " 'aidi',\n",
       " 'aigle',\n",
       " 'aigner',\n",
       " 'air',\n",
       " 'airbag',\n",
       " 'airbags',\n",
       " 'airbus',\n",
       " 'airfield',\n",
       " 'airlifted',\n",
       " 'airlines',\n",
       " 'airtime',\n",
       " 'aish',\n",
       " 'aka',\n",
       " 'akc',\n",
       " 'akim',\n",
       " 'akima',\n",
       " 'akimoto',\n",
       " 'alabama',\n",
       " 'alarm',\n",
       " 'alarmed',\n",
       " 'alarmist',\n",
       " 'alarmists',\n",
       " 'alarms',\n",
       " 'alaska',\n",
       " 'alb',\n",
       " 'albania',\n",
       " 'albatross',\n",
       " 'albers',\n",
       " 'albi',\n",
       " 'albis',\n",
       " 'alchemy',\n",
       " 'alcoholic',\n",
       " 'alda',\n",
       " 'alder',\n",
       " 'aldi',\n",
       " 'aldrin',\n",
       " 'alejandro',\n",
       " 'alerts',\n",
       " 'alexander',\n",
       " 'alexandre',\n",
       " 'alexandria',\n",
       " 'alfa',\n",
       " 'alfonso',\n",
       " 'alfred',\n",
       " 'alfredo',\n",
       " 'algae',\n",
       " 'algal',\n",
       " 'algeria',\n",
       " 'algerian',\n",
       " 'alghero',\n",
       " 'algorithm',\n",
       " 'algorithms',\n",
       " 'alien',\n",
       " 'alienated',\n",
       " 'aligning',\n",
       " 'alix',\n",
       " 'aliyev',\n",
       " 'alka',\n",
       " 'allah',\n",
       " 'alle',\n",
       " 'allege',\n",
       " 'allen',\n",
       " 'allentown',\n",
       " 'alley',\n",
       " 'alliances',\n",
       " 'allied',\n",
       " 'allude',\n",
       " 'almas',\n",
       " 'almirante',\n",
       " 'alo',\n",
       " 'alonso',\n",
       " 'alp',\n",
       " 'alphabetical',\n",
       " 'altena',\n",
       " 'alter',\n",
       " 'alteration',\n",
       " 'altering',\n",
       " 'alternately',\n",
       " 'alternatives',\n",
       " 'alto',\n",
       " 'altu',\n",
       " 'altus',\n",
       " 'alumni',\n",
       " 'alva',\n",
       " 'alvar',\n",
       " 'alves',\n",
       " 'alvin',\n",
       " 'alyssa',\n",
       " 'alzheimer',\n",
       " 'ama',\n",
       " 'amaral',\n",
       " 'amateurish',\n",
       " 'amazement',\n",
       " 'amazonas',\n",
       " 'ambassadorial',\n",
       " 'ambassadorships',\n",
       " 'ambiguity',\n",
       " 'ambition',\n",
       " 'ambitions',\n",
       " 'amble',\n",
       " 'ambler',\n",
       " 'amblin',\n",
       " 'ambulance',\n",
       " 'ambushes',\n",
       " 'amenable',\n",
       " 'amended',\n",
       " 'amending',\n",
       " 'amends',\n",
       " 'amer',\n",
       " 'american',\n",
       " 'americans',\n",
       " 'amerika',\n",
       " 'amherst',\n",
       " 'ami',\n",
       " 'amico',\n",
       " 'amigos',\n",
       " 'amish',\n",
       " 'ammo',\n",
       " 'amnesty',\n",
       " 'amon',\n",
       " 'amorphous',\n",
       " 'amos',\n",
       " 'amour',\n",
       " 'amputated',\n",
       " 'amputee',\n",
       " 'amu',\n",
       " 'amused',\n",
       " 'amusements',\n",
       " 'anaheim',\n",
       " 'anakin',\n",
       " 'analogies',\n",
       " 'analogy',\n",
       " 'analysed',\n",
       " 'analytical',\n",
       " 'analyzing',\n",
       " 'anarchists',\n",
       " 'anarchy',\n",
       " 'ancestors',\n",
       " 'anchored',\n",
       " 'ancillary',\n",
       " 'anderson',\n",
       " 'ando',\n",
       " 'andrea',\n",
       " 'andres',\n",
       " 'aneurysm',\n",
       " 'angeles',\n",
       " 'angeli',\n",
       " 'angelina',\n",
       " 'angels',\n",
       " 'angers',\n",
       " 'angle',\n",
       " 'angles',\n",
       " 'angling',\n",
       " 'angrily',\n",
       " 'anguished',\n",
       " 'anhalt',\n",
       " 'ani',\n",
       " 'ania',\n",
       " 'animation',\n",
       " 'ankara',\n",
       " 'ann',\n",
       " 'announced',\n",
       " 'announces',\n",
       " 'annoy',\n",
       " 'anoint',\n",
       " 'anons',\n",
       " 'anonymous',\n",
       " 'anopheles',\n",
       " 'ansel',\n",
       " 'anselm',\n",
       " 'answer',\n",
       " 'answered',\n",
       " 'answering',\n",
       " 'ant',\n",
       " 'antalya',\n",
       " 'anterior',\n",
       " 'antes',\n",
       " 'anthropogenic',\n",
       " 'anti',\n",
       " 'antibiotic',\n",
       " 'antibiotics',\n",
       " 'anticipated',\n",
       " 'anticipates',\n",
       " 'anticommunist',\n",
       " 'antiquated',\n",
       " 'antique',\n",
       " 'antiquities',\n",
       " 'antisemitic',\n",
       " 'antithesis',\n",
       " 'antitrust',\n",
       " 'antiwar',\n",
       " 'anton',\n",
       " 'antonio',\n",
       " 'antwerp',\n",
       " 'anwar',\n",
       " 'aol',\n",
       " 'apache',\n",
       " 'apartheid',\n",
       " 'apathetic',\n",
       " 'apathy',\n",
       " 'apogee',\n",
       " 'apologetically',\n",
       " 'apologised',\n",
       " 'apologize',\n",
       " 'apologizes',\n",
       " 'apologizing',\n",
       " 'apopka',\n",
       " 'apostate',\n",
       " 'app',\n",
       " 'appalled',\n",
       " 'appalling',\n",
       " 'appealed',\n",
       " 'appearance',\n",
       " 'appeared',\n",
       " 'appliances',\n",
       " 'applicant',\n",
       " 'applicants',\n",
       " 'applications',\n",
       " 'appointing',\n",
       " 'appointment',\n",
       " 'appreciated',\n",
       " 'apprehend',\n",
       " 'apprehended',\n",
       " 'apprehension',\n",
       " 'apprehensive',\n",
       " 'apprised',\n",
       " 'approach',\n",
       " 'approached',\n",
       " 'appropriated',\n",
       " 'appropriation',\n",
       " 'approval',\n",
       " 'approvals',\n",
       " 'approve',\n",
       " 'approvingly',\n",
       " 'aqu',\n",
       " 'aquifer',\n",
       " 'araki',\n",
       " 'arat',\n",
       " 'arbitration',\n",
       " 'arbitrator',\n",
       " 'arce',\n",
       " 'archangel',\n",
       " 'archer',\n",
       " 'archie',\n",
       " 'arching',\n",
       " 'architectural',\n",
       " 'archuleta',\n",
       " 'arge',\n",
       " 'argentina',\n",
       " 'argentine',\n",
       " 'arguments',\n",
       " 'ari',\n",
       " 'aristocracy',\n",
       " 'arj',\n",
       " 'arjun',\n",
       " 'arles',\n",
       " 'arlington',\n",
       " 'arm',\n",
       " 'armenia',\n",
       " 'armin',\n",
       " 'armor',\n",
       " 'armoured',\n",
       " 'armstrong',\n",
       " 'army',\n",
       " 'arna',\n",
       " 'arnaldo',\n",
       " 'arnie',\n",
       " 'arnold',\n",
       " 'aron',\n",
       " 'arp',\n",
       " 'arr',\n",
       " 'arra',\n",
       " 'arrangement',\n",
       " 'arranging',\n",
       " 'arrears',\n",
       " 'arrington',\n",
       " 'arrives',\n",
       " 'arriving',\n",
       " 'arroyo',\n",
       " 'ars',\n",
       " 'arse',\n",
       " 'arson',\n",
       " 'arsonists',\n",
       " 'artem',\n",
       " 'arteries',\n",
       " 'article',\n",
       " 'artifact',\n",
       " 'artillery',\n",
       " 'artist',\n",
       " 'artists',\n",
       " 'arts',\n",
       " 'artwork',\n",
       " 'arul',\n",
       " 'arunachal',\n",
       " 'arundel',\n",
       " 'arya',\n",
       " 'aryan',\n",
       " 'asai',\n",
       " 'asbestos',\n",
       " 'asda',\n",
       " 'ash',\n",
       " 'asha',\n",
       " 'ashes',\n",
       " 'ashing',\n",
       " 'ashk',\n",
       " 'asinine',\n",
       " 'aska',\n",
       " 'aslan',\n",
       " 'asp',\n",
       " 'aspartame',\n",
       " 'aspirant',\n",
       " 'assassinate',\n",
       " 'assassination',\n",
       " 'assassinations',\n",
       " 'assault',\n",
       " 'assemblies',\n",
       " 'assembly',\n",
       " 'assertion',\n",
       " 'assertiveness',\n",
       " 'assessing',\n",
       " 'asshole',\n",
       " 'assignment',\n",
       " 'assimilation',\n",
       " 'assistants',\n",
       " 'associates',\n",
       " 'assurance',\n",
       " 'asterix',\n",
       " 'asteroid',\n",
       " 'asthma',\n",
       " 'astika',\n",
       " 'astoria',\n",
       " 'astra',\n",
       " 'astronauts',\n",
       " 'asylum',\n",
       " 'ataturk',\n",
       " 'atf',\n",
       " 'atheists',\n",
       " 'athlete',\n",
       " 'ation',\n",
       " 'atlas',\n",
       " 'atm',\n",
       " 'atomic',\n",
       " 'atri',\n",
       " 'atrium',\n",
       " 'atta',\n",
       " 'attaches',\n",
       " 'attachment',\n",
       " 'attack',\n",
       " 'attackers',\n",
       " 'attacking',\n",
       " 'attainment',\n",
       " 'attar',\n",
       " 'attempted',\n",
       " 'attendant',\n",
       " 'attendees',\n",
       " 'attending',\n",
       " 'attorney',\n",
       " 'attract',\n",
       " 'attracted',\n",
       " 'attraction',\n",
       " 'attractive',\n",
       " 'attracts',\n",
       " 'attribute',\n",
       " 'attributes',\n",
       " 'atty',\n",
       " 'atz',\n",
       " 'aubin',\n",
       " 'aud',\n",
       " 'audi',\n",
       " 'audiences',\n",
       " 'audited',\n",
       " 'auditioning',\n",
       " 'aught',\n",
       " 'augment',\n",
       " 'augsburg',\n",
       " 'august',\n",
       " 'augusta',\n",
       " 'aul',\n",
       " 'aur',\n",
       " 'aurelius',\n",
       " 'ausonius',\n",
       " 'aust',\n",
       " 'austin',\n",
       " 'australia',\n",
       " 'aut',\n",
       " 'aute',\n",
       " 'authentic',\n",
       " 'authorizes',\n",
       " 'automatic',\n",
       " 'automatically',\n",
       " 'autopilot',\n",
       " 'av',\n",
       " 'avatars',\n",
       " 'ave',\n",
       " 'average',\n",
       " 'avert',\n",
       " 'averted',\n",
       " 'avi',\n",
       " 'aviation',\n",
       " 'avoidance',\n",
       " 'avrupa',\n",
       " 'awake',\n",
       " 'awakened',\n",
       " 'awakens',\n",
       " 'awan',\n",
       " 'awards',\n",
       " 'aware',\n",
       " 'awd',\n",
       " 'awful',\n",
       " 'awol',\n",
       " 'axon',\n",
       " 'ay',\n",
       " 'aya',\n",
       " 'ayatollah',\n",
       " 'ayesha',\n",
       " 'ayr',\n",
       " 'azalea',\n",
       " 'azar',\n",
       " 'azeri',\n",
       " 'azhar',\n",
       " 'azione',\n",
       " 'azzi',\n",
       " 'babcock',\n",
       " 'babylonian',\n",
       " 'babysitter',\n",
       " 'bac',\n",
       " 'bach',\n",
       " 'bacha',\n",
       " 'bachelet',\n",
       " 'bachelors',\n",
       " 'bachmann',\n",
       " 'backdrop',\n",
       " 'backfired',\n",
       " 'backhanded',\n",
       " 'backhoe',\n",
       " 'backlash',\n",
       " 'backlog',\n",
       " 'backside',\n",
       " 'backstop',\n",
       " 'backstreet',\n",
       " 'badakhshan',\n",
       " 'baden',\n",
       " 'badge',\n",
       " 'badger',\n",
       " 'baez',\n",
       " 'bafta',\n",
       " 'baggage',\n",
       " 'bags',\n",
       " 'bah',\n",
       " 'bahrain',\n",
       " 'bahraini',\n",
       " 'bahri',\n",
       " 'baht',\n",
       " 'bai',\n",
       " 'baie',\n",
       " 'bailout',\n",
       " 'bailouts',\n",
       " 'baines',\n",
       " 'bait',\n",
       " 'baiting',\n",
       " 'baja',\n",
       " 'bak',\n",
       " 'baker',\n",
       " 'bakeries',\n",
       " 'bakery',\n",
       " 'bakst',\n",
       " 'bala',\n",
       " 'balakrishnan',\n",
       " 'balcony',\n",
       " 'baldwin',\n",
       " 'balked',\n",
       " 'balkh',\n",
       " 'balks',\n",
       " 'ballet',\n",
       " 'ballo',\n",
       " 'balloon',\n",
       " 'ballot',\n",
       " 'balloting',\n",
       " 'ballots',\n",
       " 'baloch',\n",
       " 'baluchistan',\n",
       " 'bam',\n",
       " 'bandidos',\n",
       " 'bandied',\n",
       " 'banding',\n",
       " 'bandits',\n",
       " 'bangs',\n",
       " 'bani',\n",
       " 'banned',\n",
       " 'banners',\n",
       " 'banquet',\n",
       " 'bans',\n",
       " 'banting',\n",
       " 'bao',\n",
       " 'baptist',\n",
       " 'baran',\n",
       " 'barbara',\n",
       " 'barber',\n",
       " 'barbie',\n",
       " 'barbies',\n",
       " 'barbra',\n",
       " 'barca',\n",
       " 'barda',\n",
       " 'bares',\n",
       " 'bargains',\n",
       " 'bari',\n",
       " 'barker',\n",
       " 'barking',\n",
       " 'barks',\n",
       " 'barley',\n",
       " 'barn',\n",
       " 'barnaby',\n",
       " 'barnard',\n",
       " 'barnwell',\n",
       " 'baron',\n",
       " 'barr',\n",
       " 'barre',\n",
       " 'barrels',\n",
       " 'barricaded',\n",
       " 'barrie',\n",
       " 'barriers',\n",
       " 'barrio',\n",
       " 'barron',\n",
       " 'bars',\n",
       " 'bart',\n",
       " 'barth',\n",
       " 'barton',\n",
       " 'barts',\n",
       " 'baryshnikov',\n",
       " 'barzani',\n",
       " 'basal',\n",
       " 'baseball',\n",
       " 'baseballs',\n",
       " 'bases',\n",
       " 'bashing',\n",
       " 'bashir',\n",
       " 'basilica',\n",
       " 'basketball',\n",
       " 'baskets',\n",
       " 'baskin',\n",
       " 'basque',\n",
       " 'bassist',\n",
       " 'batches',\n",
       " 'bathrobe',\n",
       " 'bathroom',\n",
       " 'bathrooms',\n",
       " 'batista',\n",
       " 'batman',\n",
       " 'baton',\n",
       " 'battaglia',\n",
       " 'battering',\n",
       " 'battista',\n",
       " 'battle',\n",
       " 'battleground',\n",
       " 'battlegrounds',\n",
       " 'batu',\n",
       " 'bayern',\n",
       " 'baylor',\n",
       " 'baywatch',\n",
       " 'bazaars',\n",
       " 'bbc',\n",
       " 'bbi',\n",
       " 'bbq',\n",
       " 'bce',\n",
       " 'bci',\n",
       " 'beaches',\n",
       " 'beacon',\n",
       " 'beadle',\n",
       " 'beale',\n",
       " 'beam',\n",
       " 'beamed',\n",
       " 'bear',\n",
       " 'beasley',\n",
       " 'beast',\n",
       " 'beata',\n",
       " 'beatdown',\n",
       " 'beaten',\n",
       " 'beaver',\n",
       " 'bec',\n",
       " 'beck',\n",
       " 'becker',\n",
       " 'beckon',\n",
       " 'beckwith',\n",
       " 'bedbug',\n",
       " 'bedbugs',\n",
       " 'beds',\n",
       " 'bedtime',\n",
       " 'beebe',\n",
       " 'beech',\n",
       " 'beekeepers',\n",
       " 'beeline',\n",
       " 'beer',\n",
       " 'bees',\n",
       " 'befits',\n",
       " 'beggs',\n",
       " 'begonia',\n",
       " 'begun',\n",
       " 'behaviour',\n",
       " 'behead',\n",
       " 'behinds',\n",
       " 'bek',\n",
       " 'bel',\n",
       " 'belarusian',\n",
       " 'belarussian',\n",
       " 'beleaguered',\n",
       " 'belfast',\n",
       " 'belgians',\n",
       " 'belize',\n",
       " 'belleville',\n",
       " 'bello',\n",
       " 'belted',\n",
       " 'beltr',\n",
       " 'bemoaned',\n",
       " 'bench',\n",
       " 'benches',\n",
       " 'beneath',\n",
       " 'benedict',\n",
       " 'benefactors',\n",
       " 'benghazi',\n",
       " 'benign',\n",
       " 'bennelong',\n",
       " 'benner',\n",
       " 'bennett',\n",
       " 'benoit',\n",
       " 'bent',\n",
       " 'benton',\n",
       " 'bercow',\n",
       " 'berenstain',\n",
       " 'berk',\n",
       " 'berle',\n",
       " 'bernal',\n",
       " 'bernardino',\n",
       " 'berner',\n",
       " 'bess',\n",
       " 'besting',\n",
       " 'beta',\n",
       " 'bethesda',\n",
       " 'bethlehem',\n",
       " 'betray',\n",
       " 'betraying',\n",
       " 'betta',\n",
       " 'beverage',\n",
       " 'beyonce',\n",
       " 'bha',\n",
       " 'bhat',\n",
       " 'bhp',\n",
       " 'bias',\n",
       " 'bibi',\n",
       " 'bidding',\n",
       " 'biel',\n",
       " 'biennial',\n",
       " 'biers',\n",
       " 'bigger',\n",
       " 'bigot',\n",
       " 'bilaterally',\n",
       " 'bilbao',\n",
       " 'bild',\n",
       " 'bilder',\n",
       " 'billboards',\n",
       " 'billings',\n",
       " 'billionaire',\n",
       " 'billionaires',\n",
       " 'billions',\n",
       " 'bills',\n",
       " 'bimbo',\n",
       " 'binary',\n",
       " 'binh',\n",
       " 'binney',\n",
       " 'bins',\n",
       " 'biodiversity',\n",
       " 'biofuel',\n",
       " 'biographies',\n",
       " 'bioluminescence',\n",
       " 'biomedical',\n",
       " 'biosphere',\n",
       " 'biotechnology',\n",
       " 'bipartisan',\n",
       " 'bird',\n",
       " 'birthday',\n",
       " 'bison',\n",
       " 'bit',\n",
       " 'bitch',\n",
       " 'bits',\n",
       " 'bitterness',\n",
       " 'bk',\n",
       " 'bl',\n",
       " 'blackberry',\n",
       " 'blackbox',\n",
       " 'blackface',\n",
       " 'blackhead',\n",
       " 'blackheads',\n",
       " 'blacklisted',\n",
       " 'blackouts',\n",
       " 'blade',\n",
       " 'blagojevich',\n",
       " 'blah',\n",
       " 'blames',\n",
       " 'blanc',\n",
       " 'blanchett',\n",
       " 'blankets',\n",
       " 'blas',\n",
       " 'blasphemed',\n",
       " 'blasphemers',\n",
       " 'blasphemous',\n",
       " 'blasphemy',\n",
       " 'blasting',\n",
       " 'blatt',\n",
       " 'ble',\n",
       " 'bled',\n",
       " 'bletchley',\n",
       " 'blica',\n",
       " 'blick',\n",
       " 'blige',\n",
       " 'blight',\n",
       " 'blimp',\n",
       " 'blind',\n",
       " 'blinder',\n",
       " 'blindly',\n",
       " 'blindsided',\n",
       " 'blissful',\n",
       " 'bloc',\n",
       " 'blocher',\n",
       " 'blockade',\n",
       " 'blockaded',\n",
       " 'blockades',\n",
       " 'blockages',\n",
       " 'blockquote',\n",
       " 'blogger',\n",
       " 'blogging',\n",
       " 'blogspot',\n",
       " 'blond',\n",
       " 'blondes',\n",
       " 'blood',\n",
       " 'bloodiest',\n",
       " 'bloodshed',\n",
       " 'bloodsuckers',\n",
       " 'bloodthirsty',\n",
       " 'bloomberg',\n",
       " 'bloomington',\n",
       " 'blount',\n",
       " 'blowers',\n",
       " 'blowing',\n",
       " 'blowjob',\n",
       " 'blown',\n",
       " 'blowout',\n",
       " 'blowtorch',\n",
       " 'blu',\n",
       " 'blueberries',\n",
       " 'bluffing',\n",
       " 'blume',\n",
       " 'blumenthal',\n",
       " 'bluntly',\n",
       " 'bluster',\n",
       " 'blvd',\n",
       " 'bmi',\n",
       " 'bmj',\n",
       " 'bmw',\n",
       " 'bnp',\n",
       " 'boa',\n",
       " 'boarding',\n",
       " 'boardroom',\n",
       " 'boardrooms',\n",
       " 'boards',\n",
       " 'bod',\n",
       " 'bodied',\n",
       " 'boding',\n",
       " 'bodnar',\n",
       " 'bog',\n",
       " 'bogey',\n",
       " 'boggs',\n",
       " 'bogus',\n",
       " 'boheme',\n",
       " 'bohlen',\n",
       " 'boi',\n",
       " 'boiled',\n",
       " 'boiler',\n",
       " 'bois',\n",
       " 'boko',\n",
       " 'bolder',\n",
       " 'bole',\n",
       " 'bolger',\n",
       " 'bolivar',\n",
       " 'bolivia',\n",
       " 'bolivian',\n",
       " 'boll',\n",
       " 'bolling',\n",
       " 'bolted',\n",
       " 'bombardier',\n",
       " 'bombardments',\n",
       " 'bombards',\n",
       " 'bombs',\n",
       " 'bombshell',\n",
       " 'bombshells',\n",
       " 'bondi',\n",
       " 'bonds',\n",
       " 'boner',\n",
       " 'bonner',\n",
       " 'bonnie',\n",
       " 'bons',\n",
       " 'bonus',\n",
       " 'bony',\n",
       " 'boobs',\n",
       " 'book',\n",
       " 'booked',\n",
       " 'booker',\n",
       " 'boosters',\n",
       " 'boot',\n",
       " 'booty',\n",
       " 'bop',\n",
       " 'bora',\n",
       " 'bord',\n",
       " 'bordering',\n",
       " 'borders',\n",
       " 'borg',\n",
       " 'bork',\n",
       " 'born',\n",
       " 'borough',\n",
       " ...]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#선별된 10000개 단어\n",
    "list(sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "54a05eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_lst10000=sw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02f3e46",
   "metadata": {},
   "source": [
    "## 2) textcuboid 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f4efe4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=to_txt[:16000]\n",
    "x_test=to_txt[16000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1fcda7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_lst=[]\n",
    "for sen in x_train:\n",
    "    doc_lst.append(sen.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8219b3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lst=[]\n",
    "for sen in x_test:\n",
    "    test_lst.append(sen.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9fdcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train_data에서 문서가 갖고 있는 선별한 feauture의 수 확인\n",
    "count_lst=[]\n",
    "for i in range(16000):\n",
    "    total_feature_cnt=0\n",
    "    for j in range(10000):\n",
    "        if feature_lst10000[j] in doc_lst[i]:\n",
    "            total_feature_cnt+=1\n",
    "    count_lst.append(total_feature_cnt)\n",
    "    \n",
    "print('Train_data에서 가장 많은 feature를 가진 문서의 경우 feature',max(count_lst),' 개를 가짐')\n",
    "print('Train_data에서 가장 적은 feature를 가진 문서의 경우 feature',min(count_lst),' 개를 가짐')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785c8503",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test_data에서 문서가 갖고 있는 선별한 feauture의 수 확인\n",
    "count_lst=[]\n",
    "for i in range(4000):\n",
    "    \n",
    "    total_feature_cnt=0\n",
    "    for j in range(10000):\n",
    "        if feature_lst10000[j] in test_lst[i]:\n",
    "            total_feature_cnt+=1\n",
    "    count_lst.append(total_feature_cnt)\n",
    "    \n",
    "print('Test_data에서 가장 많은 feature를 가진 문서의 경우 feature',max(count_lst),' 개를 가짐')\n",
    "print('Test_data에서 가장 적은 feature를 가진 문서의 경우 feature',min(count_lst),' 개를 가짐')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6c4af931",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1-Channel TextCuboid 생성\n",
    "textcuboid=[]\n",
    "if cnt>-1:      #cross vaidation을 위한 2번째 이후의 시행인 경우\n",
    "    for i in train_idx:\n",
    "        frame1=np.zeros((53,768))   #(maximum number of features, 768)\n",
    "        idx_cnt=0\n",
    "        for j in range(10000):\n",
    "            if feature_lst10000[j] in doc_lst[i]:\n",
    "                #문서에서 선별한 단어(feature)의 위치를 찾아 임베딩 벡터 추출\n",
    "                frame1[idx_cnt]=np.load('./bert_embedding/train(bert)/doc%d.npy'%i)[doc_lst[i].index(feature_lst10000[j])]\n",
    "                idx_cnt+=1\n",
    "        textcuboid.append(frame1)  #train data의 일부 문서에 대한 TexrCuboid가 추가됨\n",
    "        \n",
    "    for i in range(4000):\n",
    "        frame1=np.zeros((53,768))  #(maximum number of features, 768)\n",
    "        idx_cnt=0\n",
    "        for j in range(10000):\n",
    "            if feature_lst10000[j] in test_lst[i]:\n",
    "                #문서에서 선별한 단어(feature)의 위치를 찾아 임베딩 벡터 추출\n",
    "                frame1[idx_cnt]=np.load('./bert_embedding/test(bert)/test%d.npy'%i)[test_lst[i].index(feature_lst10000[j])]\n",
    "                idx_cnt+=1\n",
    "        textcuboid.append(frame1)  #test data의 문서에 대한 TexrCuboid가 추가됨\n",
    "        \n",
    "\n",
    "    textcuboid=np.array(textcuboid)\n",
    "\n",
    "    np.save('./1-Channel textcuboid_WELFake(bert).npy',textcuboid)   \n",
    "    \n",
    "else:   #첫번째 시행인 경우\n",
    "    for i in range(16000):\n",
    "        frame1=np.zeros((53,768))   #(maximum number of features, 768)\n",
    "        idx_cnt=0\n",
    "        for j in range(10000):\n",
    "            if feature_lst10000[j] in doc_lst[i]:\n",
    "                #문서에서 선별한 단어(feature)의 위치를 찾아 임베딩 벡터 추출\n",
    "                frame1[idx_cnt]=np.load('./bert_embedding/train(bert)/doc%d.npy'%i)[doc_lst[i].index(feature_lst10000[j])]\n",
    "                idx_cnt+=1\n",
    "        textcuboid.append(frame1)\n",
    "\n",
    "    textcuboid=np.array(textcuboid)\n",
    "\n",
    "    np.save('./1-Channel textcuboid_WELFake(bert).npy',textcuboid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a3071295",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1-Channel TextCuboid 생성\n",
    "textcuboid_test=[]\n",
    "\n",
    "if cnt>-1:\n",
    "    for i in test_idx:\n",
    "        frame1=np.zeros((53,768))\n",
    "        idx_cnt=0\n",
    "        for j in range(10000):\n",
    "            if feature_lst10000[j] in doc_lst[i]:\n",
    "                frame1[idx_cnt]=np.load('./bert_embedding/train(bert)/doc%d.npy'%i)[doc_lst[i].index(feature_lst10000[j])]\n",
    "                idx_cnt+=1\n",
    "        textcuboid_test.append(frame1)\n",
    "        \n",
    "    textcuboid_test=np.array(textcuboid_test)\n",
    "    np.save('./1-Channel textcuboid_test_WELFake(bert).npy',textcuboid_test)\n",
    "    \n",
    "else:\n",
    "    for i in range(4000):\n",
    "        frame1=np.zeros((53,768))\n",
    "        idx_cnt=0\n",
    "        for j in range(10000):\n",
    "            if feature_lst10000[j] in test_lst[i]:\n",
    "                frame1[idx_cnt]=np.load('./bert_embedding/test(bert)/test%d.npy'%i)[test_lst[i].index(feature_lst10000[j])]\n",
    "                idx_cnt+=1\n",
    "        textcuboid_test.append(frame1)\n",
    "\n",
    "    textcuboid_test=np.array(textcuboid_test)\n",
    "    np.save('./1-Channel textcuboid_test_WELFake(bert).npy',textcuboid_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b995f1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
