{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "184f59ff",
   "metadata": {},
   "source": [
    "# Textcuboid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa7557ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import nltk\n",
    "import re\n",
    "import string\n",
    "import json\n",
    "import keras\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "849c1414",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:/Users/user/Desktop/bilm-tf-master/textdataset/WELFake/WELFake_Dataset.csv')\n",
    "\n",
    "df = df.dropna()\n",
    "df.isnull().sum()\n",
    "\n",
    "df.drop(columns=['Unnamed: 0'],inplace=True)\n",
    "\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "X = df.drop(columns=['label'])\n",
    "y = df['label']\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    punctuationfree=\"\".join([i for i in text if i not in string.punctuation])\n",
    "    return punctuationfree\n",
    "\n",
    "X[['title','text']] = X[['title','text']].applymap(lambda x:remove_punctuation(x))\n",
    "X[['title','text']] = X[['title','text']].applymap(lambda x:x.lower())\n",
    "\n",
    "def clean_text(text):\n",
    "    text=str(text).lower() #Converts text to lowercase\n",
    "    text=re.sub('\\d+', '', text) #removes numbers\n",
    "    text=re.sub('\\[.*?\\]', '', text) #removes HTML tags\n",
    "    text=re.sub('https?://\\S+|www\\.\\S+', '', text) #removes url\n",
    "    text=re.sub(r\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", \"\", text) #removes emojis\n",
    "    text=re.sub('[%s]' % re.escape(string.punctuation),'',text) #removes punctuations\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    return text\n",
    "\n",
    "X=X['title']+' '+X['text']\n",
    "\n",
    "X = X.apply(clean_text)\n",
    "\n",
    "X = list(X)\n",
    "\n",
    "pattern = '[^a-z ]'\n",
    "Clean_X=[]\n",
    "for sen in X:\n",
    "    Clean_X.append(re.sub(pattern, '', str(sen)))\n",
    "\n",
    "clean_df = pd.DataFrame({'Clean_X': Clean_X, 'y': y})\n",
    "\n",
    "fake_df = clean_df[clean_df['y'] == 0]\n",
    "real_df = clean_df[clean_df['y'] == 1]\n",
    "\n",
    "fake_x=list(fake_df['Clean_X'])\n",
    "real_x=list(real_df['Clean_X'])\n",
    "\n",
    "real_selected_lst = []\n",
    "fake_selected_lst = []\n",
    "\n",
    "for sen in real_x:\n",
    "    word_count = len(sen.split())\n",
    "    if 10 <= word_count < 2000:\n",
    "        real_selected_lst.append(sen)\n",
    "        \n",
    "for sen in fake_x:\n",
    "    word_count = len(sen.split())\n",
    "    if 10 <= word_count < 2000:\n",
    "        fake_selected_lst.append(sen)\n",
    "\n",
    "X=real_selected_lst[:10000]+fake_selected_lst[:10000]\n",
    "y=[0]*10000+[1]*10000\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "to_txt=x_train+x_test\n",
    "\n",
    "y=y_train+y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a3ff88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder=LabelEncoder()\n",
    "\n",
    "encoder.fit(y)\n",
    "\n",
    "label=encoder.transform(y)\n",
    "\n",
    "y_train=list(label[:16000])\n",
    "y_test=list(label[16000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "054df8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#수동으로 cross validation을 하기위한 코드\n",
    "cnt=5  #cnt가 2일때 두번째 시행\n",
    "cnt=cnt-2\n",
    "\n",
    "def exclude_list(input_list, cnt):\n",
    "    return input_list[:cnt*4000]+input_list[cnt*4000+4000:16000]\n",
    "\n",
    "if cnt>-1:\n",
    "    x_train_cnt=exclude_list(x_train,cnt)+x_test\n",
    "    y_train_cnt=exclude_list(y_train,cnt)+y_test\n",
    "    x_test_cnt=x_train[cnt*4000:cnt*4000+4000]\n",
    "    y_test_cnt=y_train[cnt*4000:cnt*4000+4000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afb3d912",
   "metadata": {},
   "outputs": [],
   "source": [
    "if cnt>-1:\n",
    "    x_train=x_train_cnt\n",
    "    y_train=y_train_cnt\n",
    "    x_test=x_test_cnt\n",
    "    y_test=y_test_cnt\n",
    "    to_txt=x_train+x_test\n",
    "    y=y_train+y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02f3e46",
   "metadata": {},
   "source": [
    "## 2) textcuboid 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f5f9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Input, Conv1D, GlobalMaxPooling1D, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ffa92ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "textcuboid=np.load('./1-Channel textcuboid_WELFake(elmo).npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55f29d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "textcuboid_test=np.load('./1-Channel textcuboid_test_WELFake(elmo).npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fee0a7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train 데이터 섞기\n",
    "\n",
    "tmp = [[x,y] for x, y in zip(textcuboid, y_train)]\n",
    "random.shuffle(tmp)\n",
    "textcuboid = [n[0] for n in tmp]\n",
    "y_train = [n[1] for n in tmp]\n",
    "textcuboid=np.array(textcuboid)\n",
    "y_train=np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ddec5841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        \"best_model_{epoch}.h5\", save_best_only=False, period=5\n",
    "    ),\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor=\"val_loss\", factor=0.5, patience=2, min_lr=0.0001\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce1b3b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = Input(shape=(391, 256))\n",
    "conv1 = Conv1D(1024, 1, padding='valid', activation='relu')(input_layer)\n",
    "pooling = GlobalMaxPooling1D()(conv1)\n",
    "pooling = Dropout(0.5)(pooling)\n",
    "x = Dense(256, activation='relu')(pooling)\n",
    "x = Dropout(0.5)(x)\n",
    "output_layer = Dense(2, activation='softmax')(x)\n",
    "model = Model(inputs=input_layer, outputs=output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de8bb000",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4cb157c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 391, 256)]        0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 391, 1024)         263168    \n",
      "                                                                 \n",
      " global_max_pooling1d (Globa  (None, 1024)             0         \n",
      " lMaxPooling1D)                                                  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               262400    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 514       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 526,082\n",
      "Trainable params: 526,082\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8fa47ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=textcuboid[1000:]\n",
    "x_val=textcuboid[:1000]\n",
    "y_train1=y_train[1000:]\n",
    "y_val=y_train[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35a26571",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "59/59 [==============================] - 3s 44ms/step - loss: 0.5204 - accuracy: 0.7918 - val_loss: 0.1633 - val_accuracy: 0.9360 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "59/59 [==============================] - 2s 36ms/step - loss: 0.1660 - accuracy: 0.9331 - val_loss: 0.0959 - val_accuracy: 0.9600 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "59/59 [==============================] - 2s 36ms/step - loss: 0.1121 - accuracy: 0.9565 - val_loss: 0.0810 - val_accuracy: 0.9610 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "59/59 [==============================] - 2s 37ms/step - loss: 0.0921 - accuracy: 0.9660 - val_loss: 0.0660 - val_accuracy: 0.9690 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "59/59 [==============================] - 2s 37ms/step - loss: 0.0771 - accuracy: 0.9702 - val_loss: 0.0614 - val_accuracy: 0.9710 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "59/59 [==============================] - 2s 37ms/step - loss: 0.0686 - accuracy: 0.9747 - val_loss: 0.0574 - val_accuracy: 0.9740 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "59/59 [==============================] - 2s 36ms/step - loss: 0.0576 - accuracy: 0.9766 - val_loss: 0.0549 - val_accuracy: 0.9760 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "59/59 [==============================] - 2s 36ms/step - loss: 0.0499 - accuracy: 0.9810 - val_loss: 0.0506 - val_accuracy: 0.9770 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "59/59 [==============================] - 2s 37ms/step - loss: 0.0440 - accuracy: 0.9842 - val_loss: 0.0488 - val_accuracy: 0.9790 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "59/59 [==============================] - 2s 37ms/step - loss: 0.0418 - accuracy: 0.9843 - val_loss: 0.0451 - val_accuracy: 0.9810 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "59/59 [==============================] - 2s 36ms/step - loss: 0.0305 - accuracy: 0.9899 - val_loss: 0.0518 - val_accuracy: 0.9780 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "59/59 [==============================] - 2s 36ms/step - loss: 0.0270 - accuracy: 0.9899 - val_loss: 0.0419 - val_accuracy: 0.9800 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "59/59 [==============================] - 2s 36ms/step - loss: 0.0229 - accuracy: 0.9914 - val_loss: 0.0440 - val_accuracy: 0.9830 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "59/59 [==============================] - 2s 36ms/step - loss: 0.0229 - accuracy: 0.9915 - val_loss: 0.0416 - val_accuracy: 0.9840 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "59/59 [==============================] - 2s 37ms/step - loss: 0.0189 - accuracy: 0.9936 - val_loss: 0.0451 - val_accuracy: 0.9830 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "59/59 [==============================] - 2s 37ms/step - loss: 0.0154 - accuracy: 0.9955 - val_loss: 0.0443 - val_accuracy: 0.9830 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "59/59 [==============================] - 2s 36ms/step - loss: 0.0120 - accuracy: 0.9961 - val_loss: 0.0465 - val_accuracy: 0.9850 - lr: 5.0000e-04\n",
      "Epoch 18/20\n",
      "59/59 [==============================] - 2s 36ms/step - loss: 0.0105 - accuracy: 0.9960 - val_loss: 0.0460 - val_accuracy: 0.9850 - lr: 5.0000e-04\n",
      "Epoch 19/20\n",
      "59/59 [==============================] - 2s 36ms/step - loss: 0.0087 - accuracy: 0.9975 - val_loss: 0.0503 - val_accuracy: 0.9820 - lr: 2.5000e-04\n",
      "Epoch 20/20\n",
      "59/59 [==============================] - 2s 36ms/step - loss: 0.0074 - accuracy: 0.9977 - val_loss: 0.0486 - val_accuracy: 0.9830 - lr: 2.5000e-04\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train1,callbacks=callbacks, epochs=20,batch_size=256,validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f7be6476",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test=np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b8710f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 1s 4ms/step - loss: 0.0498 - accuracy: 0.9843\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0497957281768322, 0.984250009059906]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(textcuboid_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eb178a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 1s 5ms/step - loss: 0.0541 - accuracy: 0.9812\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.054144486784935, 0.981249988079071]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = load_model('best_model_5.h5')\n",
    "model.evaluate(textcuboid_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e9a566",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
