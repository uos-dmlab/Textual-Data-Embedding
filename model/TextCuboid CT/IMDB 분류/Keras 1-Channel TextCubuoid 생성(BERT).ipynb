{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "184f59ff",
   "metadata": {},
   "source": [
    "# Textcuboid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "849c1414",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import nltk\n",
    "import re\n",
    "import os\n",
    "import string\n",
    "import json\n",
    "import keras\n",
    "import wordninja\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c372e2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA_PATH = \"C:/Users/user/Desktop/bilm-tf-master/textdataset/IMDB/aclImdb/train\"\n",
    "TEST_DATA_PATH = \"C:/Users/user/Desktop/bilm-tf-master/textdataset/IMDB/aclImdb/test\"\n",
    "\n",
    "def read_text_file(path):\n",
    "    labels = ['neg','pos']\n",
    "    if os.path.exists(path):\n",
    "        text=[]\n",
    "        text_label =[]\n",
    "        for directory_name in os.listdir(path):\n",
    "            if directory_name in labels:\n",
    "                label_index = labels.index(directory_name)\n",
    "                data_path = os.path.join(path,directory_name)\n",
    "                for file in os.listdir(data_path):\n",
    "                    with open(os.path.join(data_path,file),'r', encoding='utf-8') as f:\n",
    "                        text.append(f.read())\n",
    "                        text_label.append(label_index)\n",
    "        return pd.DataFrame(text,columns =['texts']),pd.DataFrame(text_label,columns =['label'])\n",
    "    \n",
    "x_train,y_train = read_text_file(TRAIN_DATA_PATH) \n",
    "x_test,y_test = read_text_file(TEST_DATA_PATH) \n",
    "\n",
    "train = pd.concat([x_train, y_train], axis=1)\n",
    "test = pd.concat([x_test, y_test], axis=1)\n",
    "\n",
    "train.drop_duplicates(inplace=True)\n",
    "test.drop_duplicates(inplace=True)\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    punctuationfree=\"\".join([i for i in text if i not in string.punctuation])\n",
    "    return punctuationfree\n",
    "\n",
    "train[['texts']] = train[['texts']].applymap(lambda x:remove_punctuation(x))\n",
    "train[['texts']] = train[['texts']].applymap(lambda x:x.lower())\n",
    "test[['texts']] = test[['texts']].applymap(lambda x:remove_punctuation(x))\n",
    "test[['texts']] = test[['texts']].applymap(lambda x:x.lower())\n",
    "\n",
    "def clean_text(text):\n",
    "    text=str(text).lower() #Converts text to lowercase\n",
    "    text=re.sub('\\d+', '', text) #removes numbers\n",
    "    text=re.sub('\\[.*?\\]', '', text) #removes HTML tags\n",
    "    text=re.sub('https?://\\S+|www\\.\\S+', '', text) #removes url\n",
    "    text=re.sub(r\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", \"\", text) #removes emojis\n",
    "    text=re.sub('[%s]' % re.escape(string.punctuation),'',text) #removes punctuations\n",
    "    #text = re.sub('\\n', '', text)\n",
    "    #text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    return text\n",
    "\n",
    "X_train = train.drop(columns=['label'])\n",
    "X_test = test.drop(columns=['label'])\n",
    "y_train = train['label']\n",
    "y_test = test['label']\n",
    "\n",
    "X_train = X_train['texts'].apply(clean_text)\n",
    "X_test = X_test['texts'].apply(clean_text)\n",
    "\n",
    "pattern = '[^a-z ]'\n",
    "Clean_X_train=[]\n",
    "Clean_X_test=[]\n",
    "\n",
    "for sen in X_train:\n",
    "    Clean_X_train.append(re.sub(pattern, '', str(sen)))\n",
    "    \n",
    "for sen in X_test:\n",
    "    Clean_X_test.append(re.sub(pattern, '', str(sen)))\n",
    "\n",
    "y_train=list(y_train)\n",
    "y_test=list(y_test)\n",
    "\n",
    "train_df = pd.DataFrame({'X_train': Clean_X_train, 'y_train': y_train})\n",
    "test_df = pd.DataFrame({'X_test': Clean_X_test, 'y_test': y_test})\n",
    "\n",
    "# 레이블 값에 따라 데이터프레임을 그룹화하고 각 그룹에서 8000개의 샘플을 랜덤하게 추출\n",
    "train_df = train_df.groupby('y_train').apply(lambda x: x.sample(n=8000, random_state=42))\n",
    "\n",
    "# 레이블 값에 따라 데이터프레임을 그룹화하고 각 그룹에서 2000개의 샘플을 랜덤하게 추출\n",
    "test_df = test_df.groupby('y_test').apply(lambda x: x.sample(n=2000, random_state=42))\n",
    "\n",
    "# 인덱스를 재설정합니다. drop=True 옵션을 사용하여 기존 인덱스를 제거합니다.\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "\n",
    "x_train = train_df['X_train'].tolist()\n",
    "y_train = train_df['y_train'].tolist()\n",
    "x_test = test_df['X_test'].tolist()\n",
    "y_test = test_df['y_test'].tolist()\n",
    "\n",
    "to_txt=x_train+x_test\n",
    "y=y_train+y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4651afcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder=LabelEncoder()\n",
    "\n",
    "encoder.fit(y)\n",
    "\n",
    "label=encoder.transform(y)\n",
    "\n",
    "y_train=list(label[:16000])\n",
    "y_test=list(label[16000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d998957d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#수동으로 cross validation을 하기위한 코드\n",
    "cnt=5  #cnt가 2일때 두번째 시행\n",
    "cnt=cnt-2\n",
    "\n",
    "def exclude_list(input_list, cnt):\n",
    "    return input_list[:cnt*2000]+input_list[cnt*2000+2000:8000]+input_list[8000:cnt*2000+8000]+input_list[cnt*2000+10000:]\n",
    "\n",
    "if cnt>-1:\n",
    "    x_train_cnt=exclude_list(x_train,cnt)+x_test\n",
    "    y_train_cnt=exclude_list(y_train,cnt)+y_test\n",
    "    x_test_cnt=x_train[cnt*2000:cnt*2000+2000]+x_train[cnt*2000+8000:cnt*2000+10000]\n",
    "    y_test_cnt=y_train[cnt*2000:cnt*2000+2000]+y_train[cnt*2000+8000:cnt*2000+10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c563192",
   "metadata": {},
   "outputs": [],
   "source": [
    "#텍스트 큐보이드 생성을 위한 인덱스\n",
    "def train_idx_list(cnt):\n",
    "    original_train_lst=[i for i in range(16000)]\n",
    "    return original_train_lst[:cnt*2000]+original_train_lst[cnt*2000+2000:8000]+original_train_lst[8000:cnt*2000+8000]+original_train_lst[cnt*2000+10000:]\n",
    "\n",
    "def test_idx_list(cnt):\n",
    "    original_train_lst=[i for i in range(16000)]\n",
    "    return original_train_lst[cnt*2000:cnt*2000+2000]+original_train_lst[cnt*2000+8000:cnt*2000+10000]\n",
    "    \n",
    "if cnt>-1:\n",
    "    train_idx=train_idx_list(cnt)\n",
    "    test_idx=test_idx_list(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5c372fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#문서 길이를 조정하는 코드 텍스트 리스트와 최대 길이를 입력하면 단어 시퀀스를 최대 길이 이내로 truncate 해줌\n",
    "def limit_words(text_list, max_words):\n",
    "    new_list = []\n",
    "    for text in text_list:\n",
    "        words = text.split()\n",
    "        if len(words) > max_words:\n",
    "            words = words[:max_words]\n",
    "        new_text = ' '.join(words)\n",
    "        new_list.append(new_text)\n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6cd3423b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#사전학습된 버트는 최대 임베딩 토큰 수(512)가 정해져 있으므로 넉넉하게 최대길이를 300으로 제한\n",
    "to_txt=limit_words(to_txt,300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39504c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#불용어 불러오기\n",
    "with open('C:/Users/user/Desktop/english.txt', 'r', encoding='utf-8') as file:\n",
    "    stopwords = [line.strip() for line in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8c0c41a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'daren', 'hadn', 'herse', 'himse', 'itse', 'mayn', 'mightn', 'mon', 'mustn', 'myse', 'needn', 'oughtn', 'shan'] not in stop_words.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer(stop_words=stopwords)\n",
    "X_dtm = vect.fit_transform(to_txt)\n",
    "X_dtm = X_dtm.toarray()\n",
    "X_new = SelectKBest(chi2, k=10000).fit(X_dtm, y)\n",
    "TorF = X_new.get_support()\n",
    "TorF\n",
    "import numpy as np\n",
    "word_view=np.array(vect.get_feature_names())\n",
    "sw=word_view[TorF]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c530d167",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aag',\n",
       " 'aames',\n",
       " 'aardman',\n",
       " 'ab',\n",
       " 'abbot',\n",
       " 'abc',\n",
       " 'abducted',\n",
       " 'abe',\n",
       " 'abhay',\n",
       " 'abhishek',\n",
       " 'abigails',\n",
       " 'abject',\n",
       " 'abominable',\n",
       " 'abomination',\n",
       " 'abominations',\n",
       " 'aborigine',\n",
       " 'aborigines',\n",
       " 'abortion',\n",
       " 'abovebr',\n",
       " 'absolute',\n",
       " 'absolutely',\n",
       " 'absorbing',\n",
       " 'absurd',\n",
       " 'absurdbr',\n",
       " 'absurdly',\n",
       " 'abu',\n",
       " 'abuses',\n",
       " 'abysmal',\n",
       " 'abysmally',\n",
       " 'academy',\n",
       " 'accent',\n",
       " 'accentbr',\n",
       " 'accents',\n",
       " 'accentsbr',\n",
       " 'accentuated',\n",
       " 'accept',\n",
       " 'acceptable',\n",
       " 'acceptance',\n",
       " 'accessible',\n",
       " 'acclaimed',\n",
       " 'accolade',\n",
       " 'accommodate',\n",
       " 'accomplices',\n",
       " 'accomplished',\n",
       " 'accountant',\n",
       " 'accurate',\n",
       " 'accused',\n",
       " 'accustomed',\n",
       " 'acharya',\n",
       " 'achieved',\n",
       " 'achievement',\n",
       " 'achievements',\n",
       " 'achieves',\n",
       " 'achilleas',\n",
       " 'acid',\n",
       " 'acidic',\n",
       " 'ackland',\n",
       " 'acquire',\n",
       " 'acquired',\n",
       " 'acs',\n",
       " 'acting',\n",
       " 'actingbr',\n",
       " 'action',\n",
       " 'actionpacked',\n",
       " 'active',\n",
       " 'activism',\n",
       " 'activist',\n",
       " 'activists',\n",
       " 'actors',\n",
       " 'actorsactresses',\n",
       " 'actual',\n",
       " 'ada',\n",
       " 'adamson',\n",
       " 'adaptationbr',\n",
       " 'adapted',\n",
       " 'adapts',\n",
       " 'add',\n",
       " 'addicted',\n",
       " 'addiction',\n",
       " 'addictions',\n",
       " 'addison',\n",
       " 'addition',\n",
       " 'additionally',\n",
       " 'addresses',\n",
       " 'adds',\n",
       " 'addy',\n",
       " 'adelaide',\n",
       " 'adele',\n",
       " 'adept',\n",
       " 'adjani',\n",
       " 'adjust',\n",
       " 'adjusted',\n",
       " 'adjusting',\n",
       " 'administrator',\n",
       " 'admiration',\n",
       " 'admired',\n",
       " 'admittedly',\n",
       " 'adolph',\n",
       " 'adorable',\n",
       " 'adore',\n",
       " 'adored',\n",
       " 'adrian',\n",
       " 'ads',\n",
       " 'adult',\n",
       " 'adults',\n",
       " 'advanced',\n",
       " 'advances',\n",
       " 'advancing',\n",
       " 'advani',\n",
       " 'advent',\n",
       " 'adventure',\n",
       " 'adventures',\n",
       " 'adversity',\n",
       " 'advertised',\n",
       " 'advice',\n",
       " 'advise',\n",
       " 'advised',\n",
       " 'aerial',\n",
       " 'aerobics',\n",
       " 'affairbr',\n",
       " 'affairs',\n",
       " 'affect',\n",
       " 'affection',\n",
       " 'affectionate',\n",
       " 'affections',\n",
       " 'affirmed',\n",
       " 'affleck',\n",
       " 'afflecks',\n",
       " 'affluent',\n",
       " 'affordable',\n",
       " 'aforementioned',\n",
       " 'africa',\n",
       " 'afterall',\n",
       " 'aftermath',\n",
       " 'afterschool',\n",
       " 'aftertaste',\n",
       " 'afterwords',\n",
       " 'age',\n",
       " 'agebr',\n",
       " 'ages',\n",
       " 'agesbr',\n",
       " 'aggie',\n",
       " 'aggravating',\n",
       " 'aghast',\n",
       " 'aging',\n",
       " 'agonizing',\n",
       " 'agony',\n",
       " 'agreed',\n",
       " 'agreeing',\n",
       " 'agreement',\n",
       " 'ahem',\n",
       " 'ahista',\n",
       " 'ahmad',\n",
       " 'aidan',\n",
       " 'aided',\n",
       " 'aids',\n",
       " 'aiello',\n",
       " 'aim',\n",
       " 'aimed',\n",
       " 'aiming',\n",
       " 'aimless',\n",
       " 'aimlessly',\n",
       " 'aircraft',\n",
       " 'aired',\n",
       " 'airline',\n",
       " 'airman',\n",
       " 'airport',\n",
       " 'aisle',\n",
       " 'aja',\n",
       " 'ajas',\n",
       " 'ajay',\n",
       " 'ak',\n",
       " 'aka',\n",
       " 'akhras',\n",
       " 'akira',\n",
       " 'akshay',\n",
       " 'alabamas',\n",
       " 'alain',\n",
       " 'alan',\n",
       " 'alarmist',\n",
       " 'alarms',\n",
       " 'alas',\n",
       " 'alaska',\n",
       " 'alastair',\n",
       " 'albert',\n",
       " 'albright',\n",
       " 'album',\n",
       " 'albums',\n",
       " 'albuquerque',\n",
       " 'alcatraz',\n",
       " 'alejandro',\n",
       " 'alekos',\n",
       " 'alexander',\n",
       " 'alexandre',\n",
       " 'alexs',\n",
       " 'alfonso',\n",
       " 'alfred',\n",
       " 'ali',\n",
       " 'alice',\n",
       " 'alien',\n",
       " 'alienate',\n",
       " 'alienator',\n",
       " 'aliens',\n",
       " 'alike',\n",
       " 'alikebr',\n",
       " 'alimony',\n",
       " 'alison',\n",
       " 'allbr',\n",
       " 'alleged',\n",
       " 'alleviate',\n",
       " 'alliance',\n",
       " 'alligator',\n",
       " 'allison',\n",
       " 'allit',\n",
       " 'alltime',\n",
       " 'alluding',\n",
       " 'allusion',\n",
       " 'almighty',\n",
       " 'alois',\n",
       " 'alok',\n",
       " 'aloof',\n",
       " 'aloud',\n",
       " 'alphonse',\n",
       " 'alright',\n",
       " 'altered',\n",
       " 'alternative',\n",
       " 'altman',\n",
       " 'altoklar',\n",
       " 'aluminium',\n",
       " 'aluminum',\n",
       " 'alvin',\n",
       " 'alvins',\n",
       " 'amalgamation',\n",
       " 'amalia',\n",
       " 'amateur',\n",
       " 'amateurish',\n",
       " 'amateurishly',\n",
       " 'amateurs',\n",
       " 'amazing',\n",
       " 'amazingbr',\n",
       " 'amazoncom',\n",
       " 'ambiguities',\n",
       " 'ambiguity',\n",
       " 'ambiguous',\n",
       " 'ambitions',\n",
       " 'ambitious',\n",
       " 'ambulance',\n",
       " 'america',\n",
       " 'american',\n",
       " 'americana',\n",
       " 'ami',\n",
       " 'amiable',\n",
       " 'amicus',\n",
       " 'ammunition',\n",
       " 'amorous',\n",
       " 'amos',\n",
       " 'amounted',\n",
       " 'amounts',\n",
       " 'amply',\n",
       " 'amrapurkar',\n",
       " 'amrita',\n",
       " 'amsterdam',\n",
       " 'amudha',\n",
       " 'amused',\n",
       " 'amy',\n",
       " 'ana',\n",
       " 'anakin',\n",
       " 'analyst',\n",
       " 'analyzed',\n",
       " 'anand',\n",
       " 'ananka',\n",
       " 'anansa',\n",
       " 'anarchy',\n",
       " 'anc',\n",
       " 'ancestor',\n",
       " 'anchors',\n",
       " 'andre',\n",
       " 'andrew',\n",
       " 'andrews',\n",
       " 'android',\n",
       " 'andy',\n",
       " 'anemic',\n",
       " 'aneta',\n",
       " 'angelique',\n",
       " 'anger',\n",
       " 'angers',\n",
       " 'angry',\n",
       " 'anil',\n",
       " 'animal',\n",
       " 'animals',\n",
       " 'animated',\n",
       " 'animation',\n",
       " 'anime',\n",
       " 'anisio',\n",
       " 'ann',\n",
       " 'anna',\n",
       " 'annakin',\n",
       " 'annas',\n",
       " 'anne',\n",
       " 'annette',\n",
       " 'annie',\n",
       " 'annik',\n",
       " 'anniversary',\n",
       " 'annoyed',\n",
       " 'annoying',\n",
       " 'annoyingbr',\n",
       " 'annoyingly',\n",
       " 'annoys',\n",
       " 'anorexia',\n",
       " 'answers',\n",
       " 'ant',\n",
       " 'antarctica',\n",
       " 'anthologies',\n",
       " 'anthology',\n",
       " 'anti',\n",
       " 'antichrist',\n",
       " 'anticipate',\n",
       " 'anticlimatic',\n",
       " 'antidote',\n",
       " 'antisemitism',\n",
       " 'antithesis',\n",
       " 'antitrust',\n",
       " 'anton',\n",
       " 'antonella',\n",
       " 'antonia',\n",
       " 'antonietta',\n",
       " 'antonio',\n",
       " 'antonioni',\n",
       " 'antwone',\n",
       " 'antz',\n",
       " 'anu',\n",
       " 'anybr',\n",
       " 'anymorebr',\n",
       " 'apartheid',\n",
       " 'apartment',\n",
       " 'apelike',\n",
       " 'apes',\n",
       " 'apex',\n",
       " 'aplomb',\n",
       " 'apollo',\n",
       " 'apollonia',\n",
       " 'apologies',\n",
       " 'apologize',\n",
       " 'apologizing',\n",
       " 'apophis',\n",
       " 'appalled',\n",
       " 'appalling',\n",
       " 'appallingly',\n",
       " 'apparatus',\n",
       " 'apparent',\n",
       " 'appealing',\n",
       " 'appearances',\n",
       " 'appears',\n",
       " 'appliances',\n",
       " 'appointment',\n",
       " 'appreciated',\n",
       " 'appreciating',\n",
       " 'appreciation',\n",
       " 'appreciative',\n",
       " 'apprehended',\n",
       " 'approach',\n",
       " 'april',\n",
       " 'apropos',\n",
       " 'aquaman',\n",
       " 'aquatic',\n",
       " 'arab',\n",
       " 'arabesque',\n",
       " 'arbitrary',\n",
       " 'archaeological',\n",
       " 'archery',\n",
       " 'archetypes',\n",
       " 'ardent',\n",
       " 'ardh',\n",
       " 'areabr',\n",
       " 'argentine',\n",
       " 'arguably',\n",
       " 'argues',\n",
       " 'arias',\n",
       " 'ariauna',\n",
       " 'ariel',\n",
       " 'aristocracy',\n",
       " 'aristorcats',\n",
       " 'arkush',\n",
       " 'arm',\n",
       " 'armand',\n",
       " 'armed',\n",
       " 'armistead',\n",
       " 'arms',\n",
       " 'arquette',\n",
       " 'arranged',\n",
       " 'arresting',\n",
       " 'arrival',\n",
       " 'arrived',\n",
       " 'arriving',\n",
       " 'arrogant',\n",
       " 'arrondissement',\n",
       " 'arrows',\n",
       " 'art',\n",
       " 'arthur',\n",
       " 'arthurs',\n",
       " 'articulate',\n",
       " 'artificiality',\n",
       " 'artist',\n",
       " 'artists',\n",
       " 'artless',\n",
       " 'artsy',\n",
       " 'arty',\n",
       " 'aryeman',\n",
       " 'ash',\n",
       " 'ashamed',\n",
       " 'ashraf',\n",
       " 'ashwar',\n",
       " 'asian',\n",
       " 'asidebr',\n",
       " 'asin',\n",
       " 'asinine',\n",
       " 'askey',\n",
       " 'asleep',\n",
       " 'asleepbr',\n",
       " 'aspirations',\n",
       " 'ass',\n",
       " 'assassinated',\n",
       " 'asses',\n",
       " 'assessment',\n",
       " 'assigned',\n",
       " 'associates',\n",
       " 'assume',\n",
       " 'assuming',\n",
       " 'assumption',\n",
       " 'assy',\n",
       " 'assys',\n",
       " 'astaire',\n",
       " 'astairerogers',\n",
       " 'asterix',\n",
       " 'asteroid',\n",
       " 'astin',\n",
       " 'astonishing',\n",
       " 'astor',\n",
       " 'astounding',\n",
       " 'astral',\n",
       " 'astronauts',\n",
       " 'astute',\n",
       " 'asylum',\n",
       " 'atari',\n",
       " 'ate',\n",
       " 'atheist',\n",
       " 'atlantis',\n",
       " 'atmosphere',\n",
       " 'atmospheric',\n",
       " 'atomic',\n",
       " 'ator',\n",
       " 'atrocious',\n",
       " 'atrocity',\n",
       " 'attaches',\n",
       " 'attacked',\n",
       " 'attacker',\n",
       " 'attacks',\n",
       " 'attempt',\n",
       " 'attempts',\n",
       " 'attention',\n",
       " 'attica',\n",
       " 'attila',\n",
       " 'attitudes',\n",
       " 'attract',\n",
       " 'attribute',\n",
       " 'atul',\n",
       " 'aubrey',\n",
       " 'audiard',\n",
       " 'audience',\n",
       " 'audiences',\n",
       " 'auditioned',\n",
       " 'auditioning',\n",
       " 'auer',\n",
       " 'augmented',\n",
       " 'august',\n",
       " 'aunt',\n",
       " 'aunts',\n",
       " 'aura',\n",
       " 'aurora',\n",
       " 'austen',\n",
       " 'australian',\n",
       " 'austrian',\n",
       " 'authentic',\n",
       " 'authorities',\n",
       " 'autograph',\n",
       " 'automatic',\n",
       " 'automatically',\n",
       " 'autopilot',\n",
       " 'autopsy',\n",
       " 'autumn',\n",
       " 'ava',\n",
       " 'availability',\n",
       " 'avenue',\n",
       " 'average',\n",
       " 'averages',\n",
       " 'avery',\n",
       " 'aviv',\n",
       " 'avoid',\n",
       " 'avoidance',\n",
       " 'avoids',\n",
       " 'awaiting',\n",
       " 'awake',\n",
       " 'awaken',\n",
       " 'award',\n",
       " 'awardbr',\n",
       " 'awards',\n",
       " 'awardsbr',\n",
       " 'awardwinning',\n",
       " 'aware',\n",
       " 'awareness',\n",
       " 'awe',\n",
       " 'aweigh',\n",
       " 'aweinspiring',\n",
       " 'awesome',\n",
       " 'awful',\n",
       " 'awfulbr',\n",
       " 'awfulness',\n",
       " 'awfulnessbr',\n",
       " 'awkward',\n",
       " 'awkwardly',\n",
       " 'awsome',\n",
       " 'ax',\n",
       " 'axel',\n",
       " 'aya',\n",
       " 'ayers',\n",
       " 'azadi',\n",
       " 'azaria',\n",
       " 'aztec',\n",
       " 'azteca',\n",
       " 'azumi',\n",
       " 'babban',\n",
       " 'babe',\n",
       " 'babel',\n",
       " 'bacall',\n",
       " 'bachchan',\n",
       " 'bachelors',\n",
       " 'bachman',\n",
       " 'backbr',\n",
       " 'backdrop',\n",
       " 'backgrounds',\n",
       " 'backstage',\n",
       " 'backula',\n",
       " 'backup',\n",
       " 'backwater',\n",
       " 'backyard',\n",
       " 'bad',\n",
       " 'badand',\n",
       " 'badbr',\n",
       " 'badbut',\n",
       " 'badder',\n",
       " 'badly',\n",
       " 'badness',\n",
       " 'baffle',\n",
       " 'baffling',\n",
       " 'bafta',\n",
       " 'bag',\n",
       " 'bagdad',\n",
       " 'bagman',\n",
       " 'bah',\n",
       " 'bahrain',\n",
       " 'bahrani',\n",
       " 'bairstow',\n",
       " 'bait',\n",
       " 'baiting',\n",
       " 'bake',\n",
       " 'bakersfield',\n",
       " 'bakshi',\n",
       " 'bakshis',\n",
       " 'balan',\n",
       " 'balance',\n",
       " 'balanced',\n",
       " 'balances',\n",
       " 'balancing',\n",
       " 'balding',\n",
       " 'balduin',\n",
       " 'baldwin',\n",
       " 'ballantine',\n",
       " 'ballroom',\n",
       " 'baloney',\n",
       " 'baloo',\n",
       " 'balsam',\n",
       " 'baltar',\n",
       " 'baltimore',\n",
       " 'bambis',\n",
       " 'banal',\n",
       " 'banality',\n",
       " 'bands',\n",
       " 'bangkok',\n",
       " 'bangs',\n",
       " 'banjos',\n",
       " 'banking',\n",
       " 'banned',\n",
       " 'banner',\n",
       " 'baptist',\n",
       " 'baptists',\n",
       " 'baraka',\n",
       " 'barbara',\n",
       " 'barber',\n",
       " 'barbera',\n",
       " 'barbra',\n",
       " 'barclay',\n",
       " 'bare',\n",
       " 'barely',\n",
       " 'barf',\n",
       " 'barfly',\n",
       " 'bargained',\n",
       " 'barjatya',\n",
       " 'barker',\n",
       " 'barnes',\n",
       " 'barney',\n",
       " 'barneys',\n",
       " 'barrel',\n",
       " 'barriers',\n",
       " 'barrister',\n",
       " 'barry',\n",
       " 'barrys',\n",
       " 'barsi',\n",
       " 'bart',\n",
       " 'bartel',\n",
       " 'basanti',\n",
       " 'base',\n",
       " 'baseball',\n",
       " 'based',\n",
       " 'basically',\n",
       " 'basinger',\n",
       " 'baskets',\n",
       " 'basra',\n",
       " 'bassanio',\n",
       " 'bassenger',\n",
       " 'bat',\n",
       " 'bates',\n",
       " 'bath',\n",
       " 'bathhouse',\n",
       " 'bathsheba',\n",
       " 'baton',\n",
       " 'bats',\n",
       " 'battery',\n",
       " 'battle',\n",
       " 'battleship',\n",
       " 'battlestar',\n",
       " 'batwoman',\n",
       " 'bauer',\n",
       " 'bava',\n",
       " 'baxter',\n",
       " 'bazza',\n",
       " 'bbcs',\n",
       " 'bdsm',\n",
       " 'beads',\n",
       " 'beale',\n",
       " 'bean',\n",
       " 'bearable',\n",
       " 'bears',\n",
       " 'beastiality',\n",
       " 'beaten',\n",
       " 'beatles',\n",
       " 'beaton',\n",
       " 'beatty',\n",
       " 'beautiful',\n",
       " 'beautifulbr',\n",
       " 'beautifully',\n",
       " 'beauty',\n",
       " 'beautybr',\n",
       " 'beban',\n",
       " 'bebe',\n",
       " 'beccket',\n",
       " 'beck',\n",
       " 'beckett',\n",
       " 'beckinsale',\n",
       " 'becky',\n",
       " 'bedknobs',\n",
       " 'beeb',\n",
       " 'beery',\n",
       " 'beethoven',\n",
       " 'beetle',\n",
       " 'befall',\n",
       " 'befriends',\n",
       " 'begat',\n",
       " 'beggars',\n",
       " 'begging',\n",
       " 'begs',\n",
       " 'beguiled',\n",
       " 'beguiling',\n",
       " 'behalf',\n",
       " 'behave',\n",
       " 'behavioral',\n",
       " 'behaviors',\n",
       " 'beijing',\n",
       " 'belching',\n",
       " 'belgrade',\n",
       " 'belief',\n",
       " 'beliefbr',\n",
       " 'believable',\n",
       " 'believably',\n",
       " 'believer',\n",
       " 'believes',\n",
       " 'belinda',\n",
       " 'bell',\n",
       " 'bella',\n",
       " 'bello',\n",
       " 'belowaverage',\n",
       " 'belushi',\n",
       " 'bend',\n",
       " 'beneath',\n",
       " 'benefits',\n",
       " 'benet',\n",
       " 'bengali',\n",
       " 'bening',\n",
       " 'benji',\n",
       " 'bennett',\n",
       " 'benoit',\n",
       " 'benot',\n",
       " 'benson',\n",
       " 'bent',\n",
       " 'benward',\n",
       " 'beowulf',\n",
       " 'berenger',\n",
       " 'berkeley',\n",
       " 'berkowitz',\n",
       " 'berlin',\n",
       " 'bernadette',\n",
       " 'bernard',\n",
       " 'bernsen',\n",
       " 'berserkers',\n",
       " 'bert',\n",
       " 'bertrand',\n",
       " 'bestbr',\n",
       " 'bestever',\n",
       " 'bestiality',\n",
       " 'bestselling',\n",
       " 'bestworst',\n",
       " 'bettany',\n",
       " 'bette',\n",
       " 'betterbr',\n",
       " 'bettie',\n",
       " 'beulah',\n",
       " 'beverages',\n",
       " 'bewitching',\n",
       " 'bey',\n",
       " 'beyonce',\n",
       " 'bfg',\n",
       " 'bgrade',\n",
       " 'bhaiyyaji',\n",
       " 'bhandarkar',\n",
       " 'bhorror',\n",
       " 'bible',\n",
       " 'biblethumping',\n",
       " 'biehn',\n",
       " 'bigelow',\n",
       " 'bigfoot',\n",
       " 'biggest',\n",
       " 'bigscreen',\n",
       " 'bigwave',\n",
       " 'bikini',\n",
       " 'biko',\n",
       " 'bikos',\n",
       " 'bilal',\n",
       " 'bilals',\n",
       " 'bilko',\n",
       " 'billed',\n",
       " 'billie',\n",
       " 'billions',\n",
       " 'bin',\n",
       " 'binder',\n",
       " 'binoche',\n",
       " 'bio',\n",
       " 'biohazard',\n",
       " 'biopic',\n",
       " 'birdie',\n",
       " 'birth',\n",
       " 'biscuit',\n",
       " 'bishop',\n",
       " 'bison',\n",
       " 'bit',\n",
       " 'bitching',\n",
       " 'bitten',\n",
       " 'bitter',\n",
       " 'bitterly',\n",
       " 'bittersweet',\n",
       " 'bix',\n",
       " 'bizarre',\n",
       " 'bizet',\n",
       " 'bjm',\n",
       " 'bjork',\n",
       " 'bjorlin',\n",
       " 'bla',\n",
       " 'black',\n",
       " 'blackadder',\n",
       " 'blackened',\n",
       " 'blackie',\n",
       " 'blacksploitation',\n",
       " 'blackwater',\n",
       " 'blackwell',\n",
       " 'blah',\n",
       " 'blahbr',\n",
       " 'blaine',\n",
       " 'blair',\n",
       " 'blairs',\n",
       " 'blaise',\n",
       " 'blake',\n",
       " 'blakey',\n",
       " 'blame',\n",
       " 'bland',\n",
       " 'blandings',\n",
       " 'blandly',\n",
       " 'blank',\n",
       " 'blanket',\n",
       " 'blaring',\n",
       " 'blasted',\n",
       " 'blasts',\n",
       " 'blatant',\n",
       " 'blatantly',\n",
       " 'bleak',\n",
       " 'bleed',\n",
       " 'blend',\n",
       " 'blending',\n",
       " 'blends',\n",
       " 'bless',\n",
       " 'blessed',\n",
       " 'blew',\n",
       " 'blier',\n",
       " 'blinding',\n",
       " 'bling',\n",
       " 'bliss',\n",
       " 'blist',\n",
       " 'bloated',\n",
       " 'blob',\n",
       " 'blond',\n",
       " 'blondell',\n",
       " 'blood',\n",
       " 'bloodbath',\n",
       " 'bloodbr',\n",
       " 'bloodied',\n",
       " 'bloodline',\n",
       " 'bloodrayne',\n",
       " 'bloodsuckers',\n",
       " 'bloodthirsty',\n",
       " 'bloody',\n",
       " 'bloom',\n",
       " 'blossoms',\n",
       " 'blown',\n",
       " 'bludgeoned',\n",
       " 'blues',\n",
       " 'blunt',\n",
       " 'blurry',\n",
       " 'blurted',\n",
       " 'blustering',\n",
       " 'bmovie',\n",
       " 'bmoviebr',\n",
       " 'bmovies',\n",
       " 'bnl',\n",
       " 'boarding',\n",
       " 'boardroom',\n",
       " 'boards',\n",
       " 'boat',\n",
       " 'boating',\n",
       " 'bobba',\n",
       " 'bobbie',\n",
       " 'bobby',\n",
       " 'body',\n",
       " 'boeing',\n",
       " 'boesman',\n",
       " 'bogarde',\n",
       " 'bogart',\n",
       " 'bogey',\n",
       " 'boggles',\n",
       " 'bogie',\n",
       " 'bogosian',\n",
       " 'boiler',\n",
       " 'bolan',\n",
       " 'bolivia',\n",
       " 'bolkan',\n",
       " 'boll',\n",
       " 'bolls',\n",
       " 'bolt',\n",
       " 'bomb',\n",
       " 'bombshells',\n",
       " 'bond',\n",
       " 'bonded',\n",
       " 'bondi',\n",
       " 'bonding',\n",
       " 'bonds',\n",
       " 'bones',\n",
       " 'bonhamcarter',\n",
       " 'boni',\n",
       " 'bonus',\n",
       " 'boobs',\n",
       " 'boogey',\n",
       " 'boogeyman',\n",
       " 'book',\n",
       " 'booker',\n",
       " 'boom',\n",
       " 'boone',\n",
       " 'boorish',\n",
       " 'boorman',\n",
       " 'boothe',\n",
       " 'boots',\n",
       " 'booze',\n",
       " 'bore',\n",
       " 'bored',\n",
       " 'boredom',\n",
       " 'boredombr',\n",
       " 'borel',\n",
       " 'borg',\n",
       " 'boring',\n",
       " 'boringbr',\n",
       " 'born',\n",
       " 'bornagain',\n",
       " 'borough',\n",
       " 'borzage',\n",
       " 'boss',\n",
       " 'bossbr',\n",
       " 'bosses',\n",
       " 'bosss',\n",
       " 'boston',\n",
       " 'bother',\n",
       " 'botherbr',\n",
       " 'bothered',\n",
       " 'bothering',\n",
       " 'bothersome',\n",
       " 'bots',\n",
       " 'bottomofthebarrel',\n",
       " 'bouchet',\n",
       " 'bounces',\n",
       " 'bound',\n",
       " 'bounds',\n",
       " 'bourne',\n",
       " 'bouvier',\n",
       " 'bowery',\n",
       " 'bowing',\n",
       " 'bowser',\n",
       " 'box',\n",
       " 'boxbr',\n",
       " 'boxcover',\n",
       " 'boxed',\n",
       " 'boxer',\n",
       " 'boxing',\n",
       " 'boy',\n",
       " 'boyce',\n",
       " 'boyd',\n",
       " 'boyer',\n",
       " 'boyfriend',\n",
       " 'boyfriends',\n",
       " 'boyhood',\n",
       " 'boyles',\n",
       " 'boys',\n",
       " 'boz',\n",
       " 'bra',\n",
       " 'bracco',\n",
       " 'bracelet',\n",
       " 'brackett',\n",
       " 'brad',\n",
       " 'bradshaw',\n",
       " 'braga',\n",
       " 'bragana',\n",
       " 'brain',\n",
       " 'brainbr',\n",
       " 'braindead',\n",
       " 'brainless',\n",
       " 'branagh',\n",
       " 'branches',\n",
       " 'brandauer',\n",
       " 'brando',\n",
       " 'brandy',\n",
       " 'braselle',\n",
       " 'brash',\n",
       " 'brashear',\n",
       " 'brashears',\n",
       " 'brat',\n",
       " 'bratty',\n",
       " 'braun',\n",
       " 'brave',\n",
       " 'braveheart',\n",
       " 'bravo',\n",
       " 'bravura',\n",
       " 'brawl',\n",
       " 'brazil',\n",
       " 'brazilian',\n",
       " 'bread',\n",
       " 'breakdancing',\n",
       " 'breaking',\n",
       " 'breakout',\n",
       " 'breakthrough',\n",
       " 'breast',\n",
       " 'breasts',\n",
       " 'breath',\n",
       " 'breathed',\n",
       " 'breathes',\n",
       " 'breathtaking',\n",
       " 'breed',\n",
       " 'breillat',\n",
       " 'brennan',\n",
       " 'brent',\n",
       " 'bressart',\n",
       " 'brian',\n",
       " 'bribes',\n",
       " 'bridge',\n",
       " 'bridges',\n",
       " 'brigadoon',\n",
       " 'brigante',\n",
       " 'brigham',\n",
       " ...]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#선별된 10000개 단어\n",
    "list(sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54a05eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_lst10000=sw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02f3e46",
   "metadata": {},
   "source": [
    "## 2) textcuboid 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4efe4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=to_txt[:16000]\n",
    "x_test=to_txt[16000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1fcda7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_lst=[]\n",
    "for sen in x_train:\n",
    "    doc_lst.append(sen.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8219b3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lst=[]\n",
    "for sen in x_test:\n",
    "    test_lst.append(sen.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c00fdd22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_data에서 가장 많은 feature를 가진 문서의 경우 feature 102  개를 가짐\n",
      "Train_data에서 가장 적은 feature를 가진 문서의 경우 feature 1  개를 가짐\n"
     ]
    }
   ],
   "source": [
    "#Train_data에서 문서가 갖고 있는 선별한 feauture의 수 확인\n",
    "count_lst=[]\n",
    "for i in range(16000):\n",
    "    total_feature_cnt=0\n",
    "    for j in range(10000):\n",
    "        if feature_lst10000[j] in doc_lst[i]:\n",
    "            total_feature_cnt+=1\n",
    "    count_lst.append(total_feature_cnt)\n",
    "    \n",
    "print('Train_data에서 가장 많은 feature를 가진 문서의 경우 feature',max(count_lst),' 개를 가짐')\n",
    "print('Train_data에서 가장 적은 feature를 가진 문서의 경우 feature',min(count_lst),' 개를 가짐')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "986eda6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_data에서 가장 많은 feature를 가진 문서의 경우 feature 83  개를 가짐\n",
      "Test_data에서 가장 적은 feature를 가진 문서의 경우 feature 2  개를 가짐\n"
     ]
    }
   ],
   "source": [
    "#Test_data에서 문서가 갖고 있는 선별한 feauture의 수 확인\n",
    "count_lst=[]\n",
    "for i in range(4000):\n",
    "    \n",
    "    total_feature_cnt=0\n",
    "    for j in range(10000):\n",
    "        if feature_lst10000[j] in test_lst[i]:\n",
    "            total_feature_cnt+=1\n",
    "    count_lst.append(total_feature_cnt)\n",
    "    \n",
    "print('Test_data에서 가장 많은 feature를 가진 문서의 경우 feature',max(count_lst),' 개를 가짐')\n",
    "print('Test_data에서 가장 적은 feature를 가진 문서의 경우 feature',min(count_lst),' 개를 가짐')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ead9a043",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1-Channel TextCuboid 생성\n",
    "textcuboid=[]\n",
    "\n",
    "if cnt>-1:  #cross vaidation을 위한 2번째 이후의 시행인 경우\n",
    "    for i in train_idx:\n",
    "        frame1=np.zeros((102,768))  #(maximum number of features, 768)\n",
    "        idx_cnt=0\n",
    "        for j in range(10000):\n",
    "            if feature_lst10000[j] in doc_lst[i]:\n",
    "                #문서에서 선별한 단어(feature)의 위치를 찾아 임베딩 벡터 추출\n",
    "                frame1[idx_cnt]=np.load('./bert_embedding/train(bert)/doc%d.npy'%i)[doc_lst[i].index(feature_lst10000[j])]\n",
    "                idx_cnt+=1\n",
    "        textcuboid.append(frame1)   #train data의 일부 문서에 대한 TexrCuboid가 추가됨\n",
    "        \n",
    "    for i in range(4000):\n",
    "        frame1=np.zeros((102,768))   #(maximum number of features, 768)\n",
    "        idx_cnt=0\n",
    "        for j in range(10000):\n",
    "            if feature_lst10000[j] in test_lst[i]:\n",
    "                #문서에서 선별한 단어(feature)의 위치를 찾아 임베딩 벡터 추출\n",
    "                frame1[idx_cnt]=np.load('./bert_embedding/test(bert)/test%d.npy'%i)[test_lst[i].index(feature_lst10000[j])]\n",
    "                idx_cnt+=1\n",
    "        textcuboid.append(frame1)   #test data의 문서에 대한 TexrCuboid가 추가됨\n",
    "        \n",
    "\n",
    "    textcuboid=np.array(textcuboid)\n",
    "\n",
    "    np.save('./1-Channel textcuboid_IMDB(bert).npy',textcuboid)   \n",
    "    \n",
    "else:   #첫번째 시행인 경우\n",
    "    for i in range(16000):\n",
    "        frame1=np.zeros((102,768))   #(maximum number of features, 768)\n",
    "        idx_cnt=0\n",
    "        for j in range(10000):\n",
    "            if feature_lst10000[j] in doc_lst[i]:\n",
    "                #문서에서 선별한 단어(feature)의 위치를 찾아 임베딩 벡터 추출\n",
    "                frame1[idx_cnt]=np.load('./bert_embedding/train(bert)/doc%d.npy'%i)[doc_lst[i].index(feature_lst10000[j])]\n",
    "        textcuboid.append(frame1)\n",
    "\n",
    "    textcuboid=np.array(textcuboid)\n",
    "\n",
    "    np.save('./1-Channel textcuboid_IMDB(bert).npy',textcuboid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e75b107",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1-Channel TextCuboid 생성\n",
    "textcuboid_test=[]\n",
    "\n",
    "if cnt>-1:\n",
    "    for i in test_idx:\n",
    "        frame1=np.zeros((102,768))   #(maximum number of features, 768)\n",
    "        idx_cnt=0\n",
    "        for j in range(10000):\n",
    "            if feature_lst10000[j] in doc_lst[i]:\n",
    "                #문서에서 선별한 단어(feature)의 위치를 찾아 임베딩 벡터 추출\n",
    "                frame1[idx_cnt]=np.load('./bert_embedding/train(bert)/doc%d.npy'%i)[doc_lst[i].index(feature_lst10000[j])]\n",
    "                idx_cnt+=1\n",
    "        textcuboid_test.append(frame1)     #train data의 일부 문서에 대한 TexrCuboid가 추가됨\n",
    "        \n",
    "    textcuboid_test=np.array(textcuboid_test)\n",
    "    np.save('./1-Channel textcuboid_test_IMDB(bert).npy',textcuboid_test)\n",
    "    \n",
    "else:\n",
    "    for i in range(4000):\n",
    "        frame1=np.zeros((102,768))   #(maximum number of features, 768)\n",
    "        idx_cnt=0\n",
    "        for j in range(10000):\n",
    "            if feature_lst10000[j] in test_lst[i]:\n",
    "                #문서에서 선별한 단어(feature)의 위치를 찾아 임베딩 벡터 추출\n",
    "                frame1[idx_cnt]=np.load('./bert_embedding/test(bert)/test%d.npy'%i)[test_lst[i].index(feature_lst10000[j])]\n",
    "                idx_cnt+=1\n",
    "        textcuboid_test.append(frame1)\n",
    "\n",
    "    textcuboid_test=np.array(textcuboid_test)\n",
    "    np.save('./1-Channel textcuboid_test_IMDB(bert).npy',textcuboid_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3071295",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
